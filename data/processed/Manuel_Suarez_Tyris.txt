# Master Class. Manuel Suarez CEO Tyris-20250704_165218-Grabación de la reunión 1 # Transcripción generada automáticamente por OpenAI Whisper # Archivo original: Master Class. Manuel Suarez. CEO Tyris-20250704_165218-Grabación de la reunión.mp4 (1028.6 MB) # Procesado en 52 segmentos el 2025-07-10 03:42:48 # Total de segmentos transcritos: 49 Empezamos la grabación y empezamos la clase. Pongo retraso, que lo miras, como haya un poco que os ha venido bien. Vale, pues, presentaros a Manuel. Él es CEO de una compañía. La semejante palabra explicará un poco qué es lo que hace. Aparte de ser CEO de una compañía en temas de inteligencia artificial, además, amigo personal, que me da suerte de que sea mi amigo. Yo considero, pues, igual que hable de Javier Pérez de la parte de la Ford, que también ha tenido relación con el tema de la automoción. No sé qué explicarás del teorio, yo no lo he visto en la presentación. Pero se dedica también a temas de visión y a temas neuronales, cosas que considero que es muy interesante y que podemos aplicar aquí y que seguramente todo lo que explique ya lo he mostrado, porque estamos al final del curso, ¿vale? Entonces, agradecerle enormemente que venga, porque además de su trabajo como dirigiendo una empresa en este aspecto, también es profesor en la universidad, por lo cual me ha tenido que hacer un hueco ahí. Y, bueno, es un placer tenerte aquí y espero que disfrutéis. Y lo que os digo siempre, exprimirle. Tenéis la oportunidad de tener a una persona que, en este caso, además, en Valencia es un referente en temas de inteligencia artificial. Pues, preguntarle, exprimirle. Y si no, lo que hago siempre, le preguntaré yo, ¿vale? Y nada, a los que estáis en remoto, lo de siempre, ¿no? Levantad la mano, si nos vemos, directamente os quitáis el micro y disparáis. Y si os podéis poner la cámara, que insisto mucho, porque yo creo que es importante que os veamos. Porque si no, al final estáis ahí y sois 2 letras y no os olvido nunca, ¿vale? Pues, nada, le doy paso, no me enrollo más. Bueno, al lío. Muy bien. Gracias, Ernesto. Bueno, antes que nada, pues, igual que estabas diciendo, Ernesto, gran amigo y gran profesional también. Lo conocéis a nivel de trayectoria profesional. Y, bueno, muy contento de estar aquí. Gracias. Y muy contento también de venir a dar una masterclass o dar una clase presencial. Porque, claro, yo he estado varios años dando clases presenciales, principalmente en Cámara de Comercio y demás. Pero luego ya tuve todo el cambio a remoto. Y a partir de ahí llevo varios años 100% remoto. Y al principio bien, pero luego todo el rato silencio, todo el rato hablando tú. No habéis entendido quién tal. Cámaras cerradas, chicos, cámaras cerradas. En fin. Entonces, nada, agradezco también tener un poquito de contacto humano, poder veros, digamos, las miradas, poder interactuar con vosotros. Un poco remarco lo que ha dicho Ernesto, de que cualquier inquietud que tengáis, cualquier duda, interés, que me lo preguntéis. Como os comentaba Ernesto, mi nombre es Manuel Suárez. Ahora os comentaré un poquito sobre mí y demás. Nosotros vamos a dar la ponencia hoy de inteligencia artificial, pero en un, digamos, ámbito muy concreto. Que es el ámbito de optimización de procesos industriales. Que es a lo que yo me he dedicado y he centrado mi carrera profesional desde el inicio. O sea, yo estaba saliendo, digamos, finalizando el máster, empezando el programa de doctorado y ya me hicieron una oferta de una empresa de robótica y ya puso posible al salir del máster ya una factoría. Entonces, toda mi carrera se ha desarrollado ahí. Y entonces es donde, digamos, tanto yo como la empresa que dirijo nos hemos centrado. Entonces, os lo digo porque la ponencia tiene un enfoque muy de optimización de procesos industriales práctico, o sea, yo no oriento estas masterclass a enfoques teóricos a nivel de machine learning, a nivel de algorítmica, a nivel de cómo se debe de generar un modelo, un algoritmo, cómo entrenarlo, sino que yo os vengo a dar un enfoque que quizás no tenéis tanto en el máster, que es un enfoque a nivel práctico de cómo gestionar la implantación de proyectos de inteligencia artificial para obtener un alto valor y un retorno en la optimización de procesos industriales. Vamos a ver tanto la parte, digamos, de data analytics o predictive analytics central de minería de dato, como vamos a ver también partes de visión artificial más central en deep learning, ¿vale? Y también vamos a ver algunos casos prácticos. Aquí no tengas miedo de meterte porque aquí hay mucha máquina, que se ha metido en detalle en estos programas de Python. Es decir, que por eso, si te tienes que meter bien y si no te quieres meter por lo que sea, no pasa nada. Pero que si te quiere meter, no tengas miedo. Estupendo. Y le metas caña. Ahora iba a tirar un poquito por el máster. Este es un máster de inteligencia artificial. ¿Qué asignaturas habéis tocado? Por su modo, ¿qué habéis visto? Estáis al final ahora mismo. Machine learning, redes neuronales, vimos un poco de Bitdata, de análisis de datos, vimos seguridad informática, visión por computadora. ¿Habéis visto? Muy bien. Procesamiento de lenguaje natural. Procesamiento de lenguaje natural. Creo que me ha faltado una más. ¿Modelos abiertos, cerrados? Modelos abiertos. Sí. OK, OK. Vale, vale, perfecto. Gente sabe lenguaje natural. Hemos metido que hay temas de la gente que ya hay. Vale, vale, perfecto. Pues, entonces, digamos que toda esa visión general la tenéis. Yo os voy a dar ese enfoque de, cuando ya tenéis toda esa visión general, cómo tenéis que proceder para todo eso hacerlo realidad. O sea, yo os voy a enseñar casos reales de fases de implantación de un proyecto de inteligencia artificial en líneas de producción. Líneas de producción en el sector de automación, en el sector metal mecánico, en el sector del agua, en el sector portuario. Vamos a ver diferentes casos. Ahí, hermano, no sé si en algún momento puede ser también muy interesante, porque tenemos gente que en el Máster se dedica a inteligencia artificial, el tema de financiación a través de Europa y todo eso. Vamos a hablar de eso. Si metes algún puntito por ahí. No tengo, pero puedo soltar un rollo muy largo. No, no muy largo, pero sí que pequeños tips que pueden venir bien de cara a. Vamos a hablar de eso, porque justo ahora la llamada que estaba atendiendo cuando estaba hablando es de un responsable de tecnología de una empresa que se le acaba de meter una empresa nueva en un consorcio para presentar un proyecto de convocatoria pública de financiación pública a la Generalitat que presentamos el lunes. Qué chulo. Y estaba ahora, mano, me la cuenta el consorcio, enséñanos cuántos. Me estaba recomendando. Entonces, os puedo contar también bastante de esto, porque nosotros como empresa de inteligencia, digamos, pura de inteligencia artificial, cuando digo pura de inteligencia artificial me refiero a que no somos una empresa que desarrolla software de gestión, este tipo de cosas o aplicaciones de visión artificial, digamos, de visión artificial convencional. Hacemos en alguna medida, pero siempre que trabajamos con visión artificial, trabajamos con toda la parte de digital. Fijaros la potencia de lo que está diciendo. Es decir, es una empresa con sede en Valencia que se dedica solo a temas de inteligencia artificial. Pocas empresas hay. Ya no te diría en Valencia solo, sino en España. Además, que tenga la solera, que no es una empresa que tiene 2 años, no es una startup que acaba de empezar, que es una empresa con solera. Y, entonces, nos. Dedicamos a eso. Hay una cosa a remarcar, que también lo digo a partners, clientes o también en ponencias, que nosotros, algo que yo traccioné mucho cuando empecé con la empresa es que fuéramos una empresa, digo, pura inteligencia artificial, que no nos dedicamos al desarrollo de web, aplicaciones móviles, arquitecturas de gestión y tal, sin inteligencia artificial, pero que le diéramos, digamos, la solución completa al cliente. Quiero decir, nosotros no nos dedicamos únicamente a la capa de algo rítmica y modelado. Y cuando generamos el modelo, se lo damos al cliente y decimos, ahí lo tiene usted, apañese con el modelo. A ver cómo le imputan los datos, cómo los pre-procesa, cómo genera todo el pipeline de ejecución, cómo controla, cómo monta el sistema de alertas, cómo hace el sistema de control de errores. O sea, nosotros lo que hacemos es ofrecemos la solución, pero ofrecemos luego la solución completa. O sea, todos los demás verticales de todo el flujo de datos del sistema de análisis, lo desarrollamos. Tenemos equipo especializado también cada uno de esos verticales. Muy bien, pues, por contaros un poquito sobre mí, tengo que leerlo porque me juego ya. Por contaros un poco sobre mí, yo soy ingeniero en informática, máster en ingeniería de computadores, especialización en computación paralela. Durante, como os comentaba, durante toda mi carrera profesional, me he centrado en sistemas de optimización, sistemas de transformación digital, siempre centrado en industria. Y la he ido orientando, yo empecé como programador. Y, de hecho, yo empecé como programador de, podemos llamarle robotero, como se dice en la JEDRA, yo era robotero. Luego pasé ya más a la rama más de bases de datos. Y luego, como soy de culo inquieto, pues, yo enseguida me ponía a hablar con los project manager o con los clientes. No sé qué, digo, mira, ¿has visto esto? Aquí podemos montar esto, voy a montar lo otro. Y empecé a, digamos, a mirar más a la parte de gestión. Y a partir de ahí, pues, se ha arrollado todo. Y me he especializado desde un primer momento en machine learning y sistemas de inteligencia artificial aplicado a procesos industriales. Durante mi carrera he tenido la suerte de poder tocar un abanico sectorial bastante amplio, ¿vale? Siempre centrado en la industria. Quiero decir, la inteligencia artificial, como sabéis, actualmente se está aplicando en todos los sectores, ¿vale? Y hay sectores que tienen muchísima tirada, muchísimo modelo de negocio y que son espectaculares, pero no son mis sectores. Quiero decir, yo no me especializo en vintage, yo no me especializo en retail, no me especializo en web, ¿vale? Yo me especializo dentro de industria. Eso sí, dentro de industria he tocado bastante espacio. O sea, yo he estado, como veis ahí, tengo bastante experiencia en automoción, en metal mecánico, en agroalimentación, sector de packaging, reciclado y en construcción. Concretamente en construcción estamos ahora con un grupo de inversión libanés donde ya hemos formalizado la creación de una nueva empresa en forma de Joint Venture que se va a especializar en sistemas de inteligencia artificial para el sector de la construcción. O sea, de alguna forma lo que estamos haciendo es que mi empresa va a hacer una extensión de la línea de negocio de construcción y pasa a la nueva Joint Venture. Luego el grupo de inversión lo que hace es poner más fuerza a comercio internacional y también una, digamos, una empresa pura de visión para el sector de defensa que lo aplican a luego construcción. que compraron previamente. Y, entonces, esta nueva formación se va a especializar únicamente en el sector de la construcción, donde es AMOS, el mantenimiento inteligente de carreteras, edificios y infraestructuras públicas. Os comentaré alguna pincelada sobre esto, tampoco me quiero centrar en eso, pero os enseñaré alguna cosa que es que es realmente interesante, tanto a nivel de dato como a nivel de visión. Aplicaciones bastante chulas y sorprendentes. Entonces, bueno, este es un poquito mi recorrido. Y, como os decía, no os cortéis en ir preguntándome durante la ponencia. ¿Qué vamos a ver hoy aquí? Pues, como os digo, principalmente un enfoque muy práctico, ¿vale? Vamos a ver, en primer lugar, una descripción general de tecnologías. Estáis en un máster de inteligencia artificial, me decís que estáis terminando ya. Voy a decir también muchas cosas que vosotros sabéis, ¿vale? Entonces, a lo mejor algunas cosas sabéis, pues, perfecto, las pasaremos un poquito más ágiles, ¿no? Voy a hacer una descripción general de las tecnologías que forman la inteligencia artificial, ¿vale? Porque la inteligencia artificial, digamos, es un concepto que está respaldado por ciertas tecnologías, ¿no? Y después, digamos, está la inteligencia artificial, las tecnologías y luego ya la última capa son las aplicaciones que se desarrollan utilizando todas esas tecnologías. A partir de ahí, vamos a pasar a ver cómo organizar los datos. Esto ya también habéis oído hablar un montón de esto. Pero quizás vais a ver un enfoque más práctico, ¿vale? Seguramente en la asignatura habéis visto, tenéis una asignatura de machine learning, ¿no? Habéis hablado de la segmentación de datos, el pre-procesamiento de datos, eliminación de outliers, overfitting, etcétera, etcétera, etcétera. Podríamos estar hablando. Eso es un concepto, digamos, teórico. Podríamos decir que eso es de libro. Pero que está, perdonadme, está de puta madre, está muy bien. Ese es el concepto de libro que tenéis que aprender. Igual que Ernesto o yo, que también estudiamos en la universidad, el máster y tal. Y tenemos que aprender la teoría, ¿vale? Pero aprendida esa teoría, luego hay ciertas capas y ciertos procesos que hay que saber organizarlos para esa teoría, poder trasladarla y hacerla realidad en entornos de producción que son extremadamente estrictos a nivel de disponibilidades de máquina, a nivel de precisión de producción, precisión de calidad, en los cuales si tú paras la línea de producción durante un minuto, hay una regla de estas que dicen en Ford que cuando paras el primer minuto, los siguientes minutos son no sé cuántos 1,000 euros anidados de pérdidas, ¿vale? Entonces, fijaros la presión que tiene un ingeniero de mi equipo de ciencia de datos que está programando y de repente para la línea. Porque tiene que, de repente, abrir el código o subir algo o hacer un update de cualquier aplicación. Entonces, todo eso, digamos, genera una serie de protocolos que tenemos que seguir de organización de datos que puede que no hayáis visto aún o no lo hayáis visto de esta forma, que es la organización más práctica que yo os decía antes. Una vez que hayamos visto esto, vamos a ver, cuando ya tenemos toda esa organización de los datos a nivel práctico, principalmente centrado, no he dicho esto, principalmente centrado en sistemas de análisis predictivo, ¿vale? Vamos a ver diferentes sistemas de integración de esos datos, de esas organizaciones de datos, ¿vale? Tenemos que garantizar, pues, eso, digamos, canales, la robustez de los datos, si hay datos faltantes, si la frecuencia de muestreo es necesaria. tema de la frecuencia de mostreos tremendamente importante, porque a nivel de teoría dicen, los datos que tenemos que coger son estos, claro. Pero según la tipología de los datos, tenemos que modificar la forma en la que adquirimos esos datos. Haremos de eso. Y luego pasaremos ya, pues, un poco a hablar de la generación de modelos de Machine Learning. Una vez que hemos organizado los datos, una vez que los tenemos integrados, vamos a ver cómo crear los modelos, insisto, con un enfoque muy práctico para ponerlos en producción. Y luego vamos a ver algunos sistemas de visión artificial muy novedosos, muy nuevos, que se están utilizando hoy en día con nuevos sensores, ¿vale? Los nuevos sensores, me doy cuenta que llevo diciéndolo ya varios años, a lo mejor entonces no son tan nuevos, pero realmente, lo digo así un poco de broma, sí que son nuevos, son muy nuevos. Porque la implantación de este tipo de dispositivos y sensórica tarda mucho hasta que se estandarice en el mercado. Os estoy hablando de sensores, por ejemplo, de visión hiperespectral. A lo mejor os han dicho algo en la asignatura de visión. Veo vuestras caras. ¿Ves esto? Me gusta. Porque esto online no lo veo. Las caras de, oh, sí, os habéis quedado todos, pues, online no lo veo. Entonces, por lo que veo. Bueno, a Jenny sí que tiene la cámara puesta y también ha visto la cara, sí. A ver, Jenny, ¿conoces la visión hiperespectral? ¿Estás muteada? Sí, ahora sí. Perdón, dime. Sí, ¿conoces la visión hiperespectral? Hiperespectral, no, no como concepto. OK, OK. ¿Alguien de la clase ha oído hablar o conoce técnicamente algo sobre la visión hiperespectral con inteligencia artificial, o sea, con modelos de deep learning? Vale, pues, OK, OK, vale. Pues, es justo lo que os decía, o sea, son sensores muy avanzados, muy novedosos. Llevan ya aplicando varios años, pero digamos que hasta que la tecnología a nivel de esas sensóricas esté madura, siguen siendo implantaciones de tecnologías muy disruptivas, muy deludidas, muy innovadoras. Entonces, vamos a ver también casos prácticos de visión hiperespectral con modelos de deep learning, ¿vale? Y luego, pues, ya vamos a hablar, os voy a enseñar, que es normalmente lo que más gusta, chicha de verdad de proyectos y de sistemas reales que he implantado. Tenía la suerte de estar muy cercano a ellos y os voy a enseñar algunas cositas muy chulas. El miércoles vimos con Javi toda la parte de lo que tiene de visión con las cámaras, cómo tiene el túnel este, con la cebra y todo eso. Sí, sí, sí. Oh, sorprendido. La cebra. Se le llama a las cámaras a la luz y, efectivamente. Sí, es que en cebra hay unas cámaras que son cebra, ¿vale? Que dice la luz estructural. Sí, sí, sí. Yo también trabajé en ese. Sí, sí, sí. Es que el chico que comenta, Javi, yo también trabajé en esa empresa durante. En Inés. ¿En Inés? ¿Que lo visteis el miércoles? Sí, yo también trabajé ahí. Y la verdad es que fue una escuela espectacular y mantengo muy buena relación también con la dirección de Inés y con gente de Inés. La verdad es que genial. Muy bien. Pues, nada. Visto esto, vamos a continuar. Para que veáis, conozcáis un poquito más sobre mí y a lo que me dedico, ¿vale? Os voy a contar qué hacemos en Tirisaí, como estaba comentando Ernesto, para que veáis, pues, una empresa valenciana tecnológica que ha empezado, empezó y se ha desarrollado de manera orgánica, únicamente con financiación privada de los socios, sin. que accede a rondas de inversión y financiándose tanto a nivel privado como a nivel de convocatoria pública de ayudas a la investigación. Ahora es cierto que ya estamos abriendo un poquito más las orejas a escuchar ciertas cosas, como, por ejemplo, la creación de esta Join Venture para construcción, que se estaba diciendo. Pero digamos que a nivel de negocio, pues hemos querido desarrollarnos así, tener 100% el control. Hemos crecido orgánicamente y hemos querido mantener el control también a nivel accionarial. Lo que sigue siendo que a través de los años hemos tenido algún propuesta, intento más o menos hostil de alguna gran corporación de nuestro país, tirando al norte, pero querían hacer el 51% y luego, aparte, sacarnos de alguno de nuestros sectores y centrarnos únicamente en metodología. Tuvimos ahí nuestros debates y discusiones de los socios y, finalmente, decidimos no acceder porque, bueno, qué tendríamos que hacer. Entonces, ahora estamos viendo, pues, como os digo, otras formas de potenciar a otro nivel que antes. Muy bien, entonces, IbiSai es una empresa de inteligencia artificial industrial. Perdonad que lo remarque otra vez, pero es que muchas veces las ponencias, ojo, tienen clase cuando en el otro máster que doy, pues, hay personas que se sorprenden, ¿no? Porque creen o tienen el concepto de inteligencia artificial, que es una aplicación en el móvil que se llama ChatCPT y hablan con él. Entonces, ahora mismo a nivel popular, a nivel comercial en el mundo, con todo el auge de OpenAI, con ChatCPT y todo esto, la gente se cree que la inteligencia artificial es hablar y que te respondan. Está muy centrado a que se creen que la inteligencia artificial son sistemas de NLP o LLM. La inteligencia artificial tiene un abanico tecnológico enorme. Casi ha superado a la medicina ya. O sea, enorme. Y hay muchísimos más ámbitos de aplicación que la gente se sorprende. Hostia, pero esto también es la inteligencia artificial. Por supuesto que sí, incluso antes del ChatCPT que estabas utilizando. Entonces, IbiSai, como os digo, somos una empresa de inteligencia artificial valenciana formada por un grupo humano en doctores en inteligencia artificial y machine learning. Tenemos actualmente 3 doctores en inteligencia artificial machine learning. El resto del equipo, científicos de datos y arquitectos de software. Obviamente, el resto del equipo técnico. Lo tenemos, pues, eso. Ketty, la administración, excelencia. A través de los años y gracias un poco a nuestro buen hacer, que le he dicho, pues, hemos sido ganadores de varios premios de innovación en tecnología aplicada. Es verdad que todos ellos, digamos, antes de la pandemia, porque también a lo mejor éramos otro tamaño de empresa y nos presentábamos más este tipo de premios. Ahora ya, digamos, miramos hacia otro lado. Y hemos ganado varios premios, todos en desarrollos de inteligencia artificial aplicado a sectores concretos. Ahora os daré alguna pincelada de alguno de ellos. ¿Cuál es el leitmotiv de Tirisai? Que somos una empresa de inteligencia artificial industrial y, por lo tanto, nos centramos, yo concretamente di bastante por culo, perdonad la expresión, sobre todo al principio, en tener gente también de optimización de procesos industriales. O sea, no solo poner científicos de datos, sino también poner científicos de datos y también ingenieros industriales especializados en sistemas de comunicación. ¿Por qué? Porque si tú montas un sistema, si tú montas un modelo de análisis predictivo, un modelo de deep learning, un sistema de simulación. un sistema de planificación inteligente, cuando incita a hacer lo que puede contar luego. Si montáis todo eso y decís, ya lo tenemos entrenado, ¿dónde están los canales de integración y las puntas de datos? Aquí, conéctalas, ya están conectados. Lo vais a montar y va a funcionar todo perfecto. Pero como la base de los datos, no hayáis tenido en cuenta ciertas cosas de calibración, frecuencias de muestreo, de artesisismo y demás, todo el sistema va a funcionar perfecto. Pero cuando empiecen a pasar los días, la precisión de los modelos no va a ser suficiente. Va a ser un sistema que no falla, pero que no predice. No predice realmente la realidad o el futuro. Y eso yo lo he visto así de veces. De ir a Michelin, por ejemplo, la primera vez que fuimos a Michelin, a la factoría Valladolid, tenían un sistema montado muy grande que venía de la central en Francia, con PAI, Dios y Soft. ¿Conocéis PAI, Dios y Soft? Es una plataforma IoT muy, muy potente que está implantada en muchos lugares del mundo y con grandes corporaciones. Y ellos tienen implantado PAI, Dios y Soft. Yo conozco a la gente de PAI de España. Hablé con ellos, nos pusimos a desarrollar todas las tapas de analítica. ¿Qué ocurrió? Falló también por nuestra parte. Consideramos o dimos por válidos todos los datos que estaban teniendo, tanto renombre y demás. ¿Qué ocurrió? No habían visto bien la naturaleza de cada una de las señales y habían tenido en cuenta ciertos aspectos de adquisición según la naturaleza de las propias señales. Por lo cual, nosotros montamos todo, funcionó todo bien, pero luego los modelos no eran lo suficientemente precisos como para implantarlos en producción. Entonces, por eso es tan importante poner también gente especializada en optimización de procesos industriales. Y eso yo creo que ha sido esa mezcla de conocimiento experto en inteligencia artificial y conocimiento de sistemas de comunicación industrial, ha sido una de nuestras claves de éxito. Pues conforme han ido pasando los años, nos hemos ido haciendo proveedores homologados de compañías como SEAD, como Michelin, como Ford, ACCIONA, SACIR, etcétera, etcétera, Ferrovial, ahora estamos. Y como os comentaba, pues estamos en automoción, infraestructuras, agua y depuración, construcción y metal mecánico. Y ahí, Manu, lo que no veo, que entiendo que es toda la parte de jefes de proyecto, quiero decir, al final, no sé si vais tipo de proyecto en cascada o tipos de proyecto, es que supongo que eso será más complicado agile, pero entiendo que no lo subcontratáis, eso, ¿no? ¿Forma parte o sí? Lo tenemos in-house. En algún caso cuando vamos en proyectos consorciados o con partners por la naturaleza del proyecto ha llevado la gestión el partner, pero normalmente toda esta gestión la llevamos nosotros. Todo el tema de metodologías agile y demás la seguimos. A mí me ha costado... Yo lo veo difícil en todo este mundo, ¿eh? Correcto. Porque la gente era muy pro, la gente era muy pro y yo también, pero fijaros que a mí me daba en la nariz como le está dando ahora Ernesto que íbamos a tener problemas y nos dimos contra un muro, ¿eh? Todo esto es aprender, o sea, todo esto es aprender e ir creciendo como empresa y como profesionales, es así. Nos dimos contra un muro. ¿Por qué? Justamente te lo hueles ya, porque es tan variable, tiene tanta complejidad acceder a diferentes tipos de procesos industriales con toda su complejidad, ver cómo estás accediendo a los datos, si es necesario poner sensórica adicional o si no, qué pasa con los controles de ánimo. máquina. Algunos de ellos están ahí desde el año catapum, o sea, luego accedes a ellos, qué naturaleza tienen, qué formato, qué unidades, cómo los vas a transformar, qué frecuencias de adquisición, etcétera, etcétera. Y luego de todo esto, ponte a modelar. Y cuando te pones a modelar, ahí dices que te sale a la primera, tienes una precisión de puta madre, pero eso es el menor número de veces, chicos. Y luego hay que aplicar diferentes estrategias de algorítmica, diferentes tipos de, pues, eso, de tanto cosas básicas como aprendizaje, digamos, supervisado o no supervisado, a luego diferentes otros tipos de estrategias, como, por ejemplo, en Machine Learning habéis trabajado Splineable. ¿Habéis visto Splineable? Pues, os voy a contar yo de Splineable. Esto es una tendencia a nivel de investigación en Europa que ya se está aplicando a nivel de Machine Learning. Algo muy moderno, pero ya muy de actualidad que lo están pidiendo mucho, Splineable Models, ¿vale? A ver, luego pues lo vamos a ver. PAULA MONTAÑA ZAMORRODO Los modelos explicables, ¿no? JUAN MANUEL LUCERO Los modelos explicables. Correcto, correcto. Explicabilidad. ¿Habéis visto? PAULA MONTAÑA ZAMORRODO No hemos visto, pero Jenny y yo sí que hemos trabajado en eso. Hola, soy Joana. JUAN MANUEL LUCERO Muy bien. En este aspecto sí que son muy bien. Estupendo. Pues, como sabréis, es una nueva tendencia ya desde hace pocos años, se está implantando cada vez más y está siendo tremendamente útil, ¿vale? Los modelos de explicabilidad en inteligencia artificial. Entonces, pues eso, a lo mejor tienen que ir a enfoques también de explicabilidad. Entonces, con todas esas pruebas. Hola, ¿qué tal? Con toda esa variabilidad de pruebas, enfoques, intentos de algorítmica, de precisiones, lo que está diciendo Ernesto, o sea, ¿cómo vas a planificar un conjunto de estudios? O sea, es muy complicado en muchas ocasiones. Entonces, lo que hacemos normalmente es, planificamos con esas metodologías lo que es la plataforma web, que eso sí que puedes decir, mira, en 2 semanas vamos a tener esto y en 2 semanas vamos a tener esto. Todo lo que es la capa de arquitectura y arquitectura web, cloud y demás, sí que lo realizamos de esa forma, pero la parte de ciencia de datos y ciencia de datos, minería hiperprocesado, suele ser más complicado. Si metes lo científico de datos, con esas metodologías, al principio no te va a sonreír, pero luego te va a empezar a mirar. Claro. Vale. Muy bien. Y luego nada. Y luego esto que tenéis aquí, pues son, digamos, algunos ejemplos de las cuentas con las que más desarrollo de negocio llevamos, más sistemas tienen nuestros implantados. Ya que estamos en Valencia, pues nosotros llevamos mucho tiempo trabajando con Ford en Valencia. Y, de hecho, estamos desarrollando ahora la plataforma global de planta de análisis predictivo, lo llaman el Site de Valencia, que es toda la factoría de Valencia, con un montón de sistemas de integración, de modelos de análisis para las 7 plantas, tanto motores, carreterías, pinturas, para todas esas plantas. Sí. Tú eres parte de la gente que abrió Kairi Seyari. Sí. Vale. ¿Cómo llegasteis a, o sea, viste que había un nicho en el que lo podíais implementar algo que era moderno? O sea, porque, claro, te estoy diciendo ahora, con la gente que trabajáis, todos los sectores, pero como pensamos que hay que llegar a. Primero que todo echándole cara, tío. Hay que echarle cara, hay que echarle valentía, proactividad. Como dicen, el síndrome del impostor siempre va a estar al principio y hay que tirar para adelante. Concretamente, como digo, es una pregunta interesante. Lo que pasó fue, por contaros, no os he dicho tampoco en qué empresas he trabajado yo previamente, pero remontándome al momento, creo. Ernesto y yo lo hemos comentado alguna vez. Yo era jefe de producto de una plataforma IoT en Aguas de Valencia, aquí, que ahora se llamaba GlobalOven. Entonces, trabajábamos con una empresa que se llamaba Tiri Software, que se dedicaban a hacer más software de gestión, aplicaciones móviles, webs, todas estas cosas. Y habían conseguido hacer algún pilotito en temas de automoción, más temas industriales. No les había salido mal, pero lo habían hecho más como, digamos, equipo interno de la empresa y habían dado pasitos. Y les empezaba a interesar. ¿Qué pasa? Que yo los conocí porque trabajamos en un proyecto conjunto y demás. Entonces, ellos empezaron a meterse, digamos, en la inception, empezaron a meterse en la cabeza la idea de que eso podía tener una tirada, ¿vale? Por los 2 proyectitos estos pequeñitos que hicieron, podía tener una tirada importante. Pero solo eran 2 proyectos, ya está. Me conocieron yo siendo jefe de producto en Aguas de Valencia y empezamos a hablar. Empezamos a hablar y, pues, nada, un día en una comida, que ellos ya me mojaron para comer eso, me dijeron que tenían esta idea y que, pero claro, que veían un sector tan competitivo, tan difícil. Fue en el 2017. O sea, que no había hecho la explosión. Exacto, fue en el 2017. Y entonces, pero que esto no lo iban a hacer sin alguien que pisara puerta en la industria, que tuviera, digamos, experiencia tecnológica, inteligencia especializada. Y me propusieron ser director para crear una empresa nueva, una división, digamos, de una nueva empresa, formación de nueva empresa, que se llamara TIRIS AI. Pues, un proceso de negociación y demás, también de participación de la empresa y todo esto. Finalmente llegamos a un acuerdo y me puse a crear. Pero éramos, claro, éramos yo y mi socio que es el director técnico, pero ya está, mirándome las caras. Y los primeros proyectos que hicimos, aparte de que yo por la relación que tenía en Ford saqué un proyecto ahí en la planta de carrocería, fue también con la constructora SACIR, un proyecto de temas de carreteras y demás al principio. Y ahí empezamos a trabajar y investigar en la creación de un motor de análisis predictivo para predecir el deterioro de los pavimentos en la red de carreteras nacional. ¿Qué pasa? Que ahí éramos muy pequeñitos. Ahí ya, digamos, 4 personas. Pero, como digo, hay que echarle cara aquí. Echarle cara y, aunque sea el símbolo del impostor, hay que tirar para delante. Entonces, dio la casualidad de que SACIR abrió, perdón, ¿conocéis el concepto de Open Innovation Programs? Estos programas de innovación abierta. Esto también a nivel de negocio y también os interesa, porque es como una puerta de entrada muy interesante a meterse en grandes compañías, que es un poco también la pregunta que estabas haciendo tú. Los programas de innovación abierta son habitualmente promovidos por grandes corporaciones o corporaciones que tienen un músculo importante, en los que, en función de todas las líneas de negocio que llevan, que son muchas, lo que hacen es decir, mira, yo tengo todo esto. Pues, ah, guau, Sabor de Valencias, SACIR, ACCIONA, Michelin, SEAD, ¿no? Yo tengo toda esta distribución de procesos. Pues, mira, voy a abrir un programa de innovación abierta y voy a hacer una llamada. a dar a todas las tecnológicas que se quieran presentar, diciéndoles el reto que tengo, diciéndoles, mira, yo tengo este problema que es que, yo me lo invento, en la línea de pinturas de Mercedes Vittoria, cuando llegan los coches a la línea de pinturas, pues siempre me están quedando defectos de calidad, o sea, no me queda la pintura uniforme y tengo un problema. Yo expongo esto para que se presenten todas las y me presenten el proyecto más ambicioso que tengan, o el más potente que tengan, y yo elegiré el ganador. Y cuando elija el ganador, tú empezarás a trabajar conmigo y te haré el proveedor oficial. ¿Pero te piden un modelo mínimo viable, un producto mínimo viable, o te piden el estudio de fiabilidad o económico y técnico? Sí, es buena pregunta. Lo segundo que acabas de decir. O sea, no, lo que te piden es tu planteamiento técnico, todo el análisis del proyecto que hayas hecho y el equipo que vas a aplicar, el cronograma de desarrollo e implantación y toda la distribución detallada de presupuesto. ¿Pero te piden la teoría? Claro, o sea, no te va, porque si no, piénsalo. Si no, dirían, vale, se han presentado, yo qué sé, para hacer ese proyecto se me han presentado 25 tecnológicas. ¿Qué van a hacer? Hacerle las 25 que desarrollen el proyecto a las 25. ¿Quién paga eso? En primer lugar. En segundo lugar, 25 proyectos se pagan, es una locura. Entonces, lo que hacen es, a las 35 lo que sí que le dicen es, hacerme todo este estudio, todo este análisis. Hacen eventos, visitas a la planta, workshops para explicarles todo. Y, entonces, esas empresas tienen que plantear toda la planteamiento técnico de negocio, cronograma, implantación, equipo y presupuesto. Y, entonces, ya después, esa corporación lo que hace es elegir el mejor planteamiento que, según su conocimiento experto, es el mejor. Y ese, finalmente, según el presupuesto que habían acordado, es el que contratan. También os digo una cosa, esto ya lo digo ya por experiencia y por daros consejos. Si adheréis a estas cosas, es una muy buena puerta de entrada, pero, ojo, porque algunas de estas grandes corporaciones están buscando sacarse la foto. Y, a veces, poco más, ¿vale? Os lo digo como consejo. Hay muchas de esas empresas que lo que hacen es, digamos, pedirte muchas cosas, hazme este planteamiento y este y este. Ojo, ese planteamiento lo vas a hacer en una tarde. Hacen meses de trabajo y de estudiar todo. Claro, ¿quién paga eso? Eso no lo paga nadie, lo pagas tú. O sea, es una inversión propia, a riesgo. Pero llega un momento que te van pidiendo más y más. ¿Por qué? Porque les queda de puta madre a ellos, luego hacer el evento que sale luego por televisión, porque estamos hablando de grandes corporaciones, de Acciona, de Mercedes y tal. Y lo presentan y le hacen el evento y lo promocionan muy práctico y a ellos les queda genial. Y también al dejar la administración pública, hostia, qué bien estás. Y estás promoviendo el trabajo, toma más dinero público, toma más dinero público, toma más dinero público. Entonces, les conviene mucho. Pero, claro, están jugando con empresas que están empezando y son muy pequeñitas. Y eso puede llegarte a ahogar. A los tiempos que vivís, a esas cosas no lo dedicas a hacer proyectos reales. Donde te facturas, ingresas, que es al final lo que te permite vivir, ¿no? Gracias. Te van pidiendo, pero al final eso lo vas a mandar a la producción, ¿no? A llegar un momento. Si te eligen. Pero es lo típico para la foto de mi mamá dirigida a mí y tal, te siguen pidiendo cosas, pero te siguen pidiendo cosas para algo que tú en un futuro supone que lo vas a implementar para ellos, ¿no? O no llega, si te eligen, insisto, si te eligen. Tanto en la primera como en la segunda cosa que me vienen o en la cuarta, ¿vale? O sea, si te eligen. Te lo digo porque es que, además, luego. Bueno, es que os puedo contar, se tiene claros y oscuros. No obstante, sí que os digo, es una muy buena puerta de entrada. Eso sí, tenéis que dejaros la piel, porque estáis compitiendo contra un montón de empresas, igual que vosotros, pues una empresa Castilla-La Mancha, otra empresa de Pascua, otra en Barcelona, otra en Barcelona, y sumáis y sigue, ¿vale? ¿Qué pasa? Que ahí, un poco volviendo a tu pregunta, yo empecé que también yo era muy espabilado, hay que ser también muy zorro y ver un poco por dónde, porque yo me estaba pegando con una división de Siemens, Inteligencia Artificial de España. Y me estaba pegando, pues, empresas mucho más grandes que yo y tal. ¿Qué hice yo? Pues cogí, me contacté con una ingeniera civil de la Universidad de Valencia, le propuse el proyecto a éxito, que luego le daba un porcentaje de presupuesto a éxito tal. Al final la convencí, se puso a trabajar conmigo y empecé a plantear toda la algorítmica con el conocimiento experto de la ingeniera de caminos en carreteras. Claro, el resto de empresas me dijeron eso. Y cuando tú le presentas a SACIR, a SACIR Concesiones, le creé a todas las carreteras, todo el planteamiento algorítmico, pero, además, en un lenguaje de la ingeniera civil que están entendiendo, el deterioro de la rugosidad de la composición del pavimento, genera, en fin, temas técnicos que ellos, aparte de la algorítmica, coño, dijeron, hostia, esto me convence más. Sobre todo, todo lo demás estoy leyendo cosas que me suenan a chino. Pues, sí, la red neuronal convolucional, la entrenaremos, pues, las restricciones convolucionales de las carreteras. O sea, eso lo va a leer SACIR y se le van a quedar los ojos bizcos para decir, pues, bien, pero cuando ya, ¿y las eso? Lo mismo que os decía de gente de utilización de procesos industriales, cuando iras eso y lo alineas con el conocimiento experto de la propia materia, ahí es cuando ganas. Y yo me moví por ahí. ¿Qué pasó? Ganamos. Y esa fue nuestra entrada a la construcción de SACIR. De hecho, está, tenéis aquí, me dio el premio Pedro Duque, que era el ministro del astronauta, era el ministro de. Ese foto no lo había visto yo. Sí, sí, sí. Ese es Manuel Manrique, el presidente de SACIR. Y Pedro Duque, cuando era ministro de innovación. Pero parece que te hayas pegado la cara, eres tú, ¿no? No lo has hecho con inteligencia artificial. Como se nota que eres amigo. No, no, o sea, claro, sí. O sea, claro, sí lo has hecho con inteligencia artificial. Pero la cara, es que tenía cara de mazapán. Ah, que es una broma. Es que tenía cara de mazapán. Pues, sí. Os tengo que decir que Pedro es igual de callado que parece. Yo intenté hablar más que el doctor técnico que estaba en la gala, que se fue a una gala por todo lo alto ahí en Madrid. Fui a hablar con él, mi doctor técnico, que es un doctor en Machine Learning. Es un científico. Claro, estar ahí con un astronauta, para él, él estaba nervioso de poder hablar con Pedro Duque. Está, bueno, vamos a hablar con Pedro, tal. Y al peor momento, que en el coctel nos acercamos. Bueno, Pedro, claro, ten en cuenta, estábamos hablando con un astronauta y el ministro de innovación de España. Claro, que tenía los dos roles. Ojo. Pues, claro, efectivamente, pues, mucha sonrisa, mucho tal. Pero al momento que te ponías a hablar con él, el mismo discurso. El gobierno apoya la innovación o no sé qué. Parecía que apretaba un botón y le salía el discurso. Igual también era inteligencia artificial. Hay una cosa importante, perdóname, que yo creo que estamos viendo durante estas masterclasses, que lo vimos también con la persona que vino de Ciber, es que la tecnología está muy bien, pero lo que lo que está diciendo Manuel también es, hay que encontrar el caso de uso funcional. funcional que le vale a la empresa. Que vale la pena hacer tecnológicamente puntera lo que tú quieras, pero hay que enfocarlo siempre a, ¿para qué? Si os acordáis que comentaba él, ¿para qué? ¿Qué necesita, en este caso, el cliente? Y en este caso, como dice él, que tiene mucha vista, vamos a ver, un especialista en tema de carreteras que habla de lo que quieren escuchar y lo que necesitan, pues, para esto. Entonces, esa es clave. Digo porque el objetivo de las masterclasses también es que veáis eso, ¿no? Que hay que enfocarlo hacia lo que necesita la empresa, ¿no? Aquello que desarrollemos. Tremendamente importante. Gracias, Pace. Pues, estuvimos, para la preparación de esto, bueno, eso es un poco por lo que os decía, ahora contesto tu pregunta, se fue el Premio de Innovación por desarrollar el motor predictivo de Machine Learning de deterioro de pavimentos. Estuvimos procesando, son 7 carreteras de España y estuvimos previamente preparando todo este planteamiento que os estaba diciendo. Estuvimos varios meses, ya te he puesto, estuvimos varios meses yo liando a las personas, tal, yendo y viniendo, montando todo eso. Pasamos varias fases, se fueron, hacen varios cortes. Primero, había no sé cuántas empresas, muchísimas empresas, fueron haciendo varios cortes. Se quedaron al final con 3 y las 3 nos llevaron ya a la gala en Madrid. Y el día de antes, no salió la filtración controlada, una filtración controlada. Me llamó un directivo de SACIR, Rubén, me llamó y me dijo, Manu, lo que te voy a decir no te lo he dicho, ¿vale? Pero es que habéis ganado. Sí, pero no lo puedes decir, ¿vale? O sea, yo ya fui a Madrid al día siguiente sabiendo que habíamos ganado. Pues eso, varios meses, mejor, unos 3 meses de más. Y luego ya, después, efectivamente, que salió de todos los medios y tal, nos contrataron en el proyecto posterior, que eran creo que unos 6 meses siguientes, el desarrollo de todo el planteamiento que habíamos hecho. Y eso fue una muy buena puerta de entrada porque a día de hoy, vamos con SACIR estoy en, estamos en diferentes secciones, SACIR Concesiones, SACIR Reconstrucción y SACIR Agua. En las 3 misiones. ¿Quién quiere más? Pero estoy en esas 3. Y fue una muy buena puerta de entrada. Por eso os digo, os recomiendo este tipo de programas, pero de forma controlada. O sea, os recomiendo que vayáis a donde veáis que pisáis fuerte de verdad para que no se utilicen, ¿vale? Y cuando veáis que hay algo en lo que podéis pisar fuerte, pisar muy fuerte. Curraroslo mucho. Porque ahí sí que podéis meter, digamos, podéis meter la pierna hasta el fondo ahí en la mesa. ¿Cómo se llama el programa que habíais dicho? Open Innovation. Programas de innovación abierta. Todas las grandes corporaciones lo suelen tener. Muy bien. Y estos son, bueno, otros premios que fuimos recibiendo en la época. También recibimos el premio Michelin. Muchos de estos de programas de innovación. Porque yo me centré al principio, lo vi una buena entrada. Y la verdad es que tuvimos mucho éxito, ¿vale? Ganamos bastantes. Ganamos un premio Michelin. Luego el premio Isaac Peral, con la petroquímica Sabic. Luego también, cuando empezamos a crecer, nos dieron el Ayuntamiento de Valencia, nos dio el premio de Mejor Empresa Tecnológica, Crecimiento y no sé qué. Uno de estos premios que dan en la noche de las telecomunicaciones valencianas, aquí en la ciudad de Sartes. Y, bueno, pues fue una época de ir creciendo, de ir presentándose a esta convocatoria, de hacer ruido, de que te vayan conociendo y demás. Y de hacer todo ese sprint de desarrollo. desarrollo de negocio. Muy bien. ¿Y qué tenemos? Pues, tenemos 2 líneas tecnológicas principales y no 3, o sea, 2 y media, ya os diré la media por qué y por qué es media. Tenemos todo el vertical y el departamento de Data Analytics, que os estaba contando. ¿En qué nos centramos en Data Analytics? Principalmente nos centramos en sistemas de análisis predictivo centrados en control predictivo de calidad y control de predictivo de fallos de máquina. Tenemos también detección inteligente de ineficiencias, esto más a nivel de línea completa. Y luego aquí está incluidos los sistemas de NLP. Esto es lo que os decía de la media. Os lo voy a dejar para el final y os lo cuento, ¿vale? Sistemas de NLP, Procesamiento de Lenguaje Natural. Y luego tenemos la parte dentro de Data Analytics, tenemos la parte de simuladores, ¿vale? ¿Conocéis el concepto de gemelo digital? Digital Twin, ¿verdad? ¿Lo conocéis? Es un concepto marketiniano, que es un gemelo digital. Tú vas a decir una cosa, tú vas a decir una cosa, y yo voy a decir una cosa. O sea, no hay, digamos, acuñado un término de qué es realmente un gemelo digital. Cada empresa, en función de sus intereses, dice una cosa, ¿vale? Es un término marketiniano, como el término industria 4.0. Entonces, ¿qué ocurre? Que nosotros, dada la naturaleza de nuestra empresa de inteligencia artificial, nosotros consideramos Digital Twin, gemelo digital, a todo sistema que permite simular de forma inteligente un proceso productivo. Si tú tienes un proceso productivo a nivel real, nosotros llamamos gemelo digital a virtualizar todo eso y poder simular de forma virtual el proceso. ¿Para qué? Para que podamos modificar todos los inputs que se le están metiendo al Digital Twin virtualizado y poder ver cómo se comportaría el proceso si le modificaras los parámetros de entrada, ver qué outputs tendría. Eso tiene una potencia brutal. Fijaros, es que yo eso, pues, lo veía, estuve en un centro de investigación varios años trabajando con el sector agroalimentario. Pues, imagina, todas las pruebas de producto de Mercadona. ¿Cuándo Mercadona? Todas las pruebas de producto de Mercadona, toda la red de interproveedores de Mercadona. Yo me acuerdo Martínez Loriente. Estaba yo ahí a tope con un proyecto de investigación de Martínez Loriente de gemelos digitales porque querían introducir nuevos tipos de producto, variaciones y demás, pero no sabían qué impacto iba a tener en su línea de producción. Desarrollamos simuladores que permitían simular virtualmente para ver todas las modificaciones que querían hacer de materia prima, de aditivos, de diferentes cortes, tipos de proceso, qué modificaciones tenían que hacer y veían cómo se comportaba la línea, qué problemas iba a tener, qué fallos en el futuro iba a tener. Es brutal. Y veía el output, veía la salida, qué fallos, qué disponibilidad de máquina, qué calidad, qué productividad, qué eficiencia. ¿Qué alternativas hay a eso? ¿Paras la producción? Coges la línea, pruebas. Martínez Loriente no sé si os ha visto, es de carne, ¿vale? Entonces, claro, paras la producción, pruebas. Y en ese momento, cada segundo, es lo que he dicho, cada segundo que pares la producción, empastas. Entonces, es la única forma de probar. O construyes una línea, que también se hace, por ejemplo, Intex lo hace para otras cosas y tal. Construyes una línea solo para pruebas que también puede ser válida. Pero, claro, entonces, ahí solo puedes hacer una prueba. Lo que plantean en DigitalTwin, ejemplo digital, perdón, es junto eso. Es, ostras, yo te cojo digitalmente y lo que hago es probar para ver qué resultado va a salir. O sea, es espectacular. En TTData tenemos. una línea completa de género digital, estaban intentando tirar hacia el tema sanitario. Imagínate decir, oye, pues si te miras el tipo de meditación, ¿cómo se va a comportar el corazón y los riñones y tal? Llevándolo al extremo, ¿no? Aquí también hay un mercado muy potente para todo el tema de inteligencia artificial y simulaciones. Totalmente. Y fijaros, fijaros, esa, así es como lo desarrollamos nosotros, como empresa de inteligencia artificial, pero platico también por lo del tema marketing, ¿ya? Lo que os decía, o sea, con empresas que cogen y promocionan productos. Gemelo digital, consideran gemelo digital a un sistema que está leyendo, que no es por quitarle de importancia para nada, un sistema que está recogiendo datos, historizándolos y mostrándolos en un dashboard en cloud. ¿Ya? ¿Ya? Gemelo digital. Pues, bueno, puedes llamarlo gemelo digital también, pero yo no entiendo eso como gemelo digital, ¿vale? Yo a todo eso, sí es parte de un gemelo digital, pero tienes que meterle un corazón de simulación, ¿vale? Lo que pasa es que, pues, sí. Sí, no, lo que tú estás comentando sería como el inicio para un gemelo digital. Porque si ya tienes todo digitalizado, tienes la información ya en un dashboard, pues, ahí ya puedes tirar y hacer un modelo y luego eso, hacer un gemelo digital y ir variándole las entradas. Es lo que entiendo yo con esto de gemelo digital. En el caso de, supongo, plantación o cría de ganado, he visto que, por ejemplo, en Uruguay casi que todas las vacas tienen chip de rastreo y todo esto. ¿Es válido hacer un gemelo digital en esos casos? No sé, de pronto para simular sequía o, por ejemplo, hacer algún modelo digital del barranco del pollo y evitar que pase lo que sucedió. Presento el lunes un proyecto de eso. Justo, justo. No es, digamos, nuestro sector. Y ahora voy a un poco a tu pregunta. No es nuestro sector porque nos dedicamos más a, digamos, industria, pero después de la DANA, digo también por lo que comentaba Ernesto antes de temas de financiación pública a 25 de abril, la Generalitat, a través de uno de sus programas de financiación pública, las tecnológicas, lo que ha hecho es, una de las convocatorias la ha estado orientando mucho a proyectos que puedan prevenir, predecir catástrofes como la que ocurrió. Esto es, si lo pensáis ahora, es también tremendamente oportunista. Claro, ahora Media Valencia el lunes va a presentar proyectos en los del barranco del pollo, de previsión de inundaciones, de desbordamiento de barrancos. Yo una de ellas. No me gustó mucho la idea, me lo presentaron mis compañeros. Mira, Manu, tenemos esta, hace 2 semanas. Tenemos esta opción, vamos a ir con Grupo Jimeno, que es una empresa de aguas, o Meno y otra empresa, tal. Vamos a presentarlo. De hecho, justamente es la pregunta que me dio la pueblo de Consorcio. Lo vamos a presentar. Son temas oportunistas, realmente. ¿Por qué? Porque saben que ahora, con todo esto que ha pasado, van a meter financiación ahí. Doctor Manés, yo estoy pensando de lo que dices. Bueno, aquí tenemos gente de Venezuela, de Colombia, en el Máster, no sé si estarán conectados, de Argentina. Claro, estos productos que vosotros estáis desarrollando, la exportación a otros países. Una vez que tienes un software desarrollado tal, es verdad que lo tienes que afinar, que esa es la clave. No tiene que ser una exportación muy complicada, ¿no? En este caso, entiendo que vosotros estáis centrados en otras cosas, que no estáis. Pero lo digo por lanzar ideas al aire de gente que tengamos estudiando. A lo mejor tenéis contacto con empresas de vuestros países. A lo mejor es una buena forma de, no digo que le quitéis la idea a Manu, ni mucho menos, sino pero de extraer esa información y poder hacer este tipo de proyectos en otros países, ¿no?, de expandirse. Yo lanzo ideas, ¿sabéis que me gusta lanzar ideas? Por supuesto. Y es algo que tenéis que tener en la cabeza. Y luego lo que comentabas es que es oportunista, es verdad. Pero, mira, ayer leía yo que el mar Mediterráneo está ahora mismo a 30 grados. Lo dijo mi madre ayer, que es el que mayor impacto está teniendo en el cambio climático. 30 grados. Es decir, si esto no cambia de la temperatura, y es difícil porque normalmente siempre va a más, con suerte se mantiene, es decir, la gota fría que podría llegar a esperar este año podría ser monumental. Que eso no quiere decir que a lo mejor se concentre como pasó de 600 litros en pocas horas, ¿no? Pero este tipo, siendo oportunista, es verdad que desde mi punto de vista va a ir a más. Entonces, puede ser un buen chollo tener esto aquí para luego, para que esos modelos creo que serán mucho más complicados de extrapolarlo a otros sitios, ¿no? Pero yo creo que es un negocio, claro, el aprovechar este tipo de inversión aquí para luego llevarlo a otro lado. Y sobre todo, si además aporta. Siendo oportunista, que estoy comentando de acuerdo. Sí, sí. Digo que es oportunista un poco por la decisión final que tomé de decir, vamos a censarlo. Porque si os fijáis, nosotros no somos especialistas, digamos, no aceptamos, digamos, sectores industriales. Temas de inundaciones, temas medioambientales, pues tampoco podemos hacerlo bien. Sí, pero que es importante también centrarse en la estrategia de empresa y lo que pasa es que, en este caso, estaba esto ahí, estaba la oportunidad y, bueno, pues tomémosla, tomémosla al final. La pregunta a nivel de, sí, de Gemelo Digital. Efectivamente, tú estabas comentando diferentes casos. No sé tu nombre, bueno, el último alumno que he preguntado. Estabas contando diferentes casos. Alejandro. Alejandro, sí. Sí, o sea, quiero decir, se puede simular también como Gemelo Digital esos casos que has dicho. Como poderse se puede, o sea, pero hay que encontrar una viabilidad. Quiero decir, tú puedes simular todo, pero luego tienes que tener resultados precisos en esa simulación. Pero efectivamente, igual que lo estamos simulando en procesos industriales, en el sector médico, como comentaba Ernesto, pues también se puede hacer en el sector agrario, en el sector medioambiental, etcétera, etcétera. Pero, obviamente, teniendo en cuenta sobre todo los nichos de las fuentes de datos que son tremendamente diferentes. O sea, sector medioambiental a leer datos de un PLC, de un controlador, de una máquina de mecanizado, pues es completamente diferente. Muy bien. Pues, nada, eso respecto al vertical de Predictive Analytics, centrado en análisis predictivo, gemelos digitales y simuladores. Y luego tenemos la parte de visión. Parte de visión artificial, como os decía, centrada en deep learning. En algún caso hacemos visión artificial más convencional, por decirlo así, convencional no significa que no sea potente, pero es, digamos, más convencional, por ejemplo, lo que comentó el ponente anterior, excompañero mío de trabajo y amigo también, Chavi. Digamos, visión artificial más convencional. Muy potente. Bueno, yo conozco el sistema de inspección del túnel y también participé en menor medida en su desarrollo cuando estaba en la empresa, pero que también lo conozco. Es muy potente, es una visión artificial, digamos, más convencional. Lo que hace el túnel es un sistema de metrología, ¿vale? Le han metido también control de calidad ahora a nivel de la superficie, pero básicamente metrología, ¿vale? Medir distancias y demás. Entonces, nosotros lo que hacemos es trabajar con sistemas basados en redes neuronales, centrados en control de calidad, en defectos dimensionales, todo el tema del vehículo eléctrico, muy importante ahora cuando las baterías estén abiertas en la línea de producción, estamos garantizando todo el tema de las conexiones eléctricas y defectos superficiales. Y luego estamos toda la parte de sistemas de control, seguridad, sistemas de videovigilancia con las redes de cámaras de CCTV, de videovigilancia indoor y outdoor, ¿vale? O sea, fuera de factoría y dentro de factoría. Tengo un ejemplo claro que no sé si os lo he puesto de un proyecto muy chulo en la Autoridad Portuaria de Valencia. El momento que los coches entran a la zona portuaria, las cámaras de videovigilancia empiezan a crear huellas digitales identificativas de cada vehículo. Una red neuronal genera una huella digital identificativa de cada vehículo y luego otra red neuronal de tracking traquea la posición de cada vehículo. Y esto no lo hacemos por la matrícula. La red neuronal genera esta huella digital identificativa como la genera un humano por el recuerdo del objeto coche. Nosotros si estamos aquí y vamos a pasar un coche, vamos a pasar un pello azul con una rascada en la parte derecha y el faro despolgado. Nosotros si nos vamos a otra punta de Valencia y de repente pasa un pello, está perfecto, no lleva ese tipo, no es el mismo, pero si vemos el pello con el faro despolgado, aquí pasa este coche. Y no nos hemos fijado en la matrícula, pero hemos identificado ese coche. Pues lo que está haciendo esta red neuronal está generando esa huella digital, ese recuerdo y luego está traqueando el recuerdo. Lo que estamos haciendo es, si os fijáis, como estamos utilizando la red de cámaras de videovigilancia del puerto, cuando el camión pasa por una cámara, genera el primer recuerdo del camión y la red dice, vale, este camión está aquí, pero llega un momento que ese camión ya sale de la zona de visión de la cámara y ya has perdido al camión. Pero luego de repente el camión aparece por la zona de visión de otra cámara. La red neuronal tiene que decir, vale, de todas las huellas identificativas que yo he creado, de todos mis recuerdos, ¿cuál es el que más se parece a este? Y dice, hostia, es este. Pero lo que hace luego es una cosa que está súper bien y nos hemos tirado bastante tiempo desarrollándolo es, se reentrena automáticamente. La red neuronal está diciendo, este es el coche que yo había recordado por primera vez antes o el vehículo, el camión, pero ahora lo estoy viendo desde otro ángulo y con otras condiciones de iluminación. Voy a recordarlo también de esta forma. Entonces, lo que va haciendo es perfeccionando el recuerdo de la huella digital identificativa conforme va cambiando de cámaras. Se va haciendo cada vez más preciso el recuerdo de ese vehículo. Sí. Yo creo que la ventaja tiene esto con que antes hubo la matrícula, que sea el ordenador de la matrícula. Puede. Esa pregunta también está bien y, digamos, tiene sentido al principio. Pero luego, o sea, es que esa misma pregunta la hice yo. Yo estaba pensando lo mismo. Al director de innovación de la auditoría portuaria. Claro, o sea, estamos hablando de toda el área del puerto de Valencia. Se lee la matrícula. Hay un lector de matrículas. En el acceso sur hay un lector de matrícula. Entonces, ahí se lee la matrícula. Pero a partir de ahí ya no se vuelve a leer la matrícula. O sea, ¿qué tienen que hacer? ¿Poner lectores de matrícula cada 10 metros? ¿Quieres que venga la cámara? No, no, claro. Las cámaras que te estoy diciendo que se entrena esta red son cámaras de videovigilancia de la Policía Portuaria de Valencia. Son cámaras que están arriba, o sea, tú no ves ahí, no puedes ver la matrícula en ningún momento. ¿Viabilidad de hacer esto sin inteligencia artificial? Sí. Pon un lector de matrículas a pie de la vía, pero pon tropecientos lectores de matrícula que va a costar. O sea, eso es inviable a nivel de costes. Entonces, este sistema se conecta a las cámaras de videovigilancia de la Policía Portuaria y aprende como un humano. Es como si hubieran cientos de humanos así mirando las cámaras diciendo, mira, aquí está pasando esto. Y habían bromas porque la red neuronal empezaba a identificar cosas que eran muy curiosas. Y hay empresas de transporte que cogen y tienen 50 camiones exactamente iguales. Un camión Pegasus con la cabina blanca, con la carga tal, iguales, o sea, ¿cómo diferencias eso? Incluso un humano, ¿cómo diferencias eso? ¿Sabes cómo se diferencia? Y lo diferenciaba la red neuronal, que era la hostia. ¿Sabéis que los camioneros ponen letras en la cabina? El nombre de la mujer, amo a Pepa. Estos personales que te colocan. Yo veía imágenes y me decía, mi equipo, me decía, bueno, mira, estamos, ¿se ha podido diferenciar esto, esto? Y digo, ¿por qué? Porque aquí pone amo a Pepa. Por esas tonterías empezaban a diferenciarse y a poder trackear todos los camiones. Entonces, a partir de ahí, fijaros la potencia que tiene esto. Tienes el control de todos los vehículos en temporal. En cualquier momento puedes encontrar dónde está cada camión. Y luego, aparte, si lo pensáis ya a nivel de negocio, que eso es importante que vayáis pensando de todo lo que genera la inteligencia artificial, si tenéis el control y el conocimiento de dónde está todos los vehículos que han accedido a toda la zona portuaria en todo momento, tenéis las rutas que están siguiendo. Y si tenéis las rutas, podéis historizarlas. Y si las historizáis, podéis entrenar un modelo ya, ya no de visión, sino de dato, de análisis predictivo. Y si podéis hacer eso, podéis predecir el tráfico en el puerto. Y eso es lo que hicimos. Pero, bueno, que me voy extendiendo, porque, claro, os puedo contar historias, historias. Pero fijaros, estos son temas de, exacto, que generan un valor directo al industrio, al mercado. Y se me estaba ocurriendo ahí que los chinos lo están haciendo, el tema de que está prohibido la nueva ley y tal, que igual que lo haces para camiones, lo haces para personas. Y con esto ya aprovechando, porque aquí realmente, yo tenía la misma pregunta que Radu. Y realmente aquí, entonces, es reaprovechar las infraestructuras de cámaras que tienes. Con lo cual, bueno, si haces eso, pues, podrías estar aquí en las cámaras que hay en la universidad y saber quién estamos viniendo, quién no. Controlar ciertos temas que al principio en China son más laxos para estas cosas. Y aquí no son tan laxos. De hecho, me han tirado proyectos. Han tirado proyectos, una gran cadena de supermercados, no me he quedado en la competencia. Un proyecto, creo que te lo comenté, dentro de los supermercados de controlar a las personas, pero era para robos, comportamientos violentos y no sé qué más. Y yo garanticé anonimizar todo el sistema, ¿vale? En el momento que pasa la primera, cuando llega la cámara, digamos, el streaming de vídeo, antes de ser procesado, se busca lo que llaman los científicos de datos. el objeto persona y se blu-raya la cabeza. Entonces, veías como a muñecos que tenían la cabeza blu-rayada y se iban moviendo por ahí. Y ya todo el sistema, el pipeline de ejecución de modelos, se hacía todo con la cabeza blu-rayada. Pues, esta, era con cinco, me lo voy a decir. Esta empresa me decía, vale, Manu, de puta madre. Y yo estaba en una gran colaboración con la UPV, este proyecto, presentando ahí todo. Estamos ya, esto, sin desarrollar aún el proyecto. Todo esto era el análisis previo que estaba haciendo yo. Todo ya presentado y se metió al departamento jurídico y dijo, es que Mercadona intentó hacer esto hace 2 años y la agencia de protección de. No, lo hizo. Se gastaron un pastizal, te digo, porque estaba yo ahí. O les metieron luego un puro. Y les metieron 5 millones o algo así. Correcto. Y que no, porque no sé qué. Y era, pero no era lo mismo, que es lo que decía yo. Digo, soy conocedor de eso, pero Mercadona lo que hizo, además de estos face detection, que es lo que no hacemos aquí. Y no hacemos face detection. Pero no querían. Pero el departamento jurídico, solo hablar de que salieran personas ya, se ponían tensos por lo que le había pasado a Mercadona. Pero es que no tiene ningún tipo de aplicación. Pues, ¿sabéis qué pasó? Me tiré varios meses peleando idas, venidas, no sé qué. Fue un proyecto paralizado, por tonterías así. ¿Por comportamiento de la persona? ¿Perdón? ¿Por comportamiento de la persona? ¿La culpa que lleva? Claro, ¿cómo se? Por el objeto persona y era, en primer lugar, hay diferentes fases. Hay un primer modelo que lo que hace es detectarte el objeto persona, como digo. Una vez que después de haber blu-rearlo. Cuando lo detecta, lo segmenta. Segmenta, se queda solo, digamos, el cuerpo. Cuando se queda el cuerpo, efectivamente. Hay una detección por CNN, o sea, por redes neuronales convolucionales, que detecta ese objeto y lo diferencia de otros por toda la ropa que lleva en ese momento y otra serie de características de todas las capas de neuronas. Toda la distribución de colores, pero también la textura que está encontrando, la volumetría, la relación de distancias entre el hombro, el codo y la muñeca y demás. Luego, después, metíamos otro modelo que lo que hacía es un modelo de esqueletic maternal, no me acuerdo exactamente el nombre. Se generaba la extracción de la esqueletización de ese objeto persona, ¿vale? Generaba, extraía todo el esqueleto que principalmente era un cálculo de distancias entre los vértices de tu esqueleto. Y a partir de ahí, como tienes el cálculo de distancia de los vértices de tu esqueleto, puedes calcular qué tipo de posiciones estás cogiendo y puedes entrenar todo el conjunto de datos de las posiciones para sacar patrones de comportamiento concretos de comportamientos violentos. Muy bien. Es que ya estamos hablando tanto. Es que este es el punto en el cual os presentéis y tal, pero es que si no, se nos va a ir a tardes. Vale. Pues, es que estamos hablando de todo que hemos hablado ya de muchas cosas porque aquí normalmente digo, ¿qué es la inteligencia artificial en la industria? Por lo que os digo, que la gente tiene mucho humo en la cabeza de lo que es, ¿vale? Que si son robots en líneas de producción haciendo tareas de operarios y demás, no es para nada eso. Hay que quitar todo el humo de lo que es la inteligencia artificial en la industria. ¿Y qué es? ¿Cómo podríamos sintetizar lo que se conoce como inteligencia artificial en la industria? Ahora estamos empezando, esto es el principio de la ponencia. Pero, bueno, la verdad es que con todo lo que hemos contado, realmente, he contado muchas cosas ya en la propia ponencia. Pero, ¿es que esto? Esto es lo bueno y es por esto me gusta dar clases presenciales, porque se genera esta interacción que yo creo que es muy, muy valiosa. Yo, digamos, acuño lo que es inteligencia artificial en industria como sistemas inteligentes que se ejecutan de manera autónoma o semiautónoma llegando a conclusiones concretas para situaciones actuales, lo que se conoce como detecciones, o situaciones futuras, lo que se conoce como predicciones. Eso es como a nivel práctico como lo hago. A partir de ahí, hay toda una serie de tecnologías, muy también a nivel marketingiano, como el concepto industria 4.0, que giran en torno a los nuevos sistemas que se están implantando en la industria. Sistemas de robótica autónoma, sistemas de simulación, big data, realidad aumentada, etcétera, etcétera, etcétera. Si os fijáis, en todo este rosco no vemos inteligencia artificial en ningún lado. ¿Por qué? ¿En todos o? Correcto. Porque se ha extendido tanto, al principio, en todos estos roscos se llamaba IA, no sé qué, pero es que ya se ha extendido tanto que en todas estas tecnologías, que no son tecnologías, son tipos de aplicaciones, en realidad, está de forma transversal la inteligencia artificial. Tenemos 3 niveles en inteligencia artificial, a nivel tecnológico, ¿lo conocéis ya? ¿Vale? Y, además, el mismo, los dos son el mismo, pero muy parecido, ¿no? Seguimos, vamos a pasarlo. Y luego, pues, esto no voy a pasar porque también lo habéis visto, ¿vale? Lo que es concretamente el machine learning, el que se hace automático en campo de la ciencia de computación, el CCTC, empezar esto, IA, el deep learning, que sabéis que es ya el subpunto de algoritmos ya donde se trabaja con redes neuronales. Tengo una pregunta. ¿Qué es lo que diferencia, qué es el concepto principal que diferencia que sea más adecuado utilizar algoritmos de machine learning o redes neuronales? Eso es difícil, ¿eh? ¿Qué hace cuando tú eres un científico de datos o un proyect manager de una empresa en inteligencia artificial y te diga, tenemos este proyecto, ¿qué utilizamos? Machine learning o deep learning. ¿Cuál es la pregunta que tenéis que hacer? ¿Qué es la que diferenciará si vais por un camino u otro? Los de online también podéis, ¿eh? Si levantáis la mano. Es muy importante los recursos disponibles. ¿Qué es lo que tienes con recursos? Hardware. Lo mismo que yo vaya a implementar un modelo de redes neuronales para una industria que va a necesitar mucha liquidez para la, digamos, para el procesamiento gráfico, un proceso mediográfico. Algo concreto, pequeño, por ejemplo, que pudiese poderlo resolver con un modelo de machine learning convencional. Vale. No es exactamente eso. Es una de las variables. No es exactamente eso, pero digamos la base. O sea, los que estáis en remoto, ¿cuál es la diferencia? Esto ya es cantidad también a nivel teórico, ¿eh? Es lo de los libros. O sea, no es más caja negra que otra. Para mí los datos estructurados, no estructurados, sería como algo en lo que me fijaría. Porque si tengo datos estructurados, voy a ir por lo más simple, el machine learning. Pero si ya es un dato más complejo, si tengo, por ejemplo, datos multimodales, entonces ya me tendría que ir por deep learning. Y obviamente también necesito saber qué recursos hay. Obviamente el deep learning requiere mucho más GPU, mucho más tiempo de entrenamiento. Pero yo me fijaría en los datos primero, porque hay problemas que tú no los puedes resolver con machine learning. Simplemente no puedes. Pero lo que te dicen, lo que a nosotros nos han enseñado, es que siempre tenemos un problema. que ir por la solución más sencilla y si ya esa no nos da, entonces ya vamos escalando en tecnología. Correcto, correcto. Todo lo que habéis dicho es válido y es cierto. No es la respuesta que estoy buscando, pero bordea, todo bordea lo que estáis diciendo. Es casi eso. La capacidad de alimentarse de las redes neuronales, digamos, porque el machine learning ya es un nivel predictivo. También es cierto, pero ¿cuál es la principal diferencia? Es que lo habéis dicho, el tipo de aplicación, el tipo de datos... Sí, pero perdona, tenéis que levantar la mano. Gregorio la tiene allí. Dispara, estás en muti, ¿eh? Bocó, hola. Sí, sí, yo creo que depende del objetivo, lo que se quiera. Todo depende de qué modelo vas a implantar, depende de lo que quieras conseguir, cuál es el objetivo. O sea, como algo genérico, pues no, y depende de si tienes pocos o muchos datos. ¿Cómo lo clavéis? Ah, ahí está. Quiero decir, todo gira en torno a eso, pero la diferencia, digamos, sin edulcorar la nominal, es que tengas pocos datos o un montonazo de datos. Eso es la palanca de cambio de ML a DL. A partir de ahí todo está relacionado con lo que habéis dicho. Pues sí, pues qué tipo de aplicación, que se puede realimentar, que hay datos multimodales, sí. Pero la palanca de cambio es, si tengo datos, no muchos, no hemos podido muestrear todo lo que nos hubiera gustado y demás, pueden buscar estrategias, estrategias de anomaly detection, que ahora os comentaré algunas muy, muy interesantes, de modelos de anomaly detection o, bueno, estrategias de clusterización o muy interesantes, ¿no? Supervisadas, no supervisadas, con machine learning. Pero en ningún momento, en ese caso, en ningún momento te pongas a utilizar una red neuronal porque no vas a sacar absolutamente nada. Porque la red neuronal, lo que está buscando la red neuronal, es alimentarse de cantidades ingentes de datos. Si no, no vas a sacar ningún tipo de resultado preciso y viable. Eso es muy, muy importante. Modelos más precisos, Big Data, tal, como ha comentado, creo que ha comentado la compañera, pues el coste computacional, utilizar neural networks, obviamente, y la necesidad de utilizar GPUs, por supuesto, o clusters de procesamiento. Déjame que lance una pregunta ahí. ¿Quién de los que estamos aquí ha escuchado el concepto de NPU? ¿Os suena alguno, NPU? Es que lo vais a escuchar, ¿eh? Próximamente. Y NPU viene esa, bueno, dejad de criticar esto, pero creo que lo comenté en alguna clase. Estamos yendo ahora a la tendencia a ir a los, a la edge computing de toda la vida, es decir, a los dispositivos finales, por hablar, por no ponerle tanto nombre, ¿vale? ¿Qué pasa? Que los dispositivos finales, como sabéis, necesitas GPUs, ¿vale? Es un problema. Entonces, empresas como Dell ya están, de hecho lo van a sacar ahora en breve, sacando otro tipo de microchip que se llama NPU, ¿vale? Que al final es N viene de neuronal. Entonces, es sacando para poder tener sistemas específicos y silicio, ¿vale? Específico para inteligencia artificial. Y la forma de medirlo es con un concepto que se llama TOP, ¿vale? De esto ya hablaremos un poco más en detalle, porque lo estamos leyendo esta semana. Pero, básicamente, establecen que el mínimo de TOPs que puedes tener para empezar a utilizar inteligencia artificial es a partir de 40 o 50 TOPs. Entonces, bueno, a ver si esta semana le doy un poquito más de cariño este fin de semana y la semana que viene comentamos. Vamos un poco de este tema, ¿vale? Que creo que es bastante interesante que acabemos. PABLO SANGUINETTI Es más, uno de los requisitos de los Copilot PC, por ejemplo, es tener una NPU que pueda tener, creo que son 30 tops. MIGUEL BURGUETE ¿Muy bien, muy bien? PABLO SANGUINETTI Lo que es todo lo de AI. MIGUEL BURGUETE Cuando te pones cámara, no te veo. PABLO SANGUINETTI Pero sí, y aparte, lo único de sí de que tienen los NPUs, que son neural processors, es que es solo para inferencia. Si vos querías hacer training y otras cosas, ya. Muy bien, muy bien puntualizado, eso no lo he dicho. Pero, efectivamente. MIGUEL BURGUETE Ya sé, ahora, con ese dato ya sé a lo que te refieres. Sí, sí, sí. Estamos también en un proyecto de investigación con SEAC de esto. PABLO SANGUINETTI Pero esto es solo para dispositivos tipo portátiles, tipo servidores. MIGUEL BURGUETE Para hacerse el bebido, pero también la electrónica modificada para eso. PABLO SANGUINETTI Claro, claro, por eso decía, se habla a nivel de silicio de este nuevo avance y está en cuestión de meses y ahora sistemas baratos. O sea, barato estoy hablando de que si una GPU o una tarjeta gráfica puede estar en torno a 3,000 euros, una buena, de esto estamos hablando ya de cientos de euros. MIGUEL BURGUETE Claro, pero esto es solo para inferencia. PABLO SANGUINETTI Ya, ya, pero pensad que al final los dispositivos finales lo que quieres es la inferencia, no quieres entregar nada. Entonces, justo es y, claro, ¿qué es lo que pasa? Que estás llevándote todos esos procesos de calorificación de datacenters, te los estás llevando al dispositivo final, que es, digamos, hacia donde tiene la tendencia ahora, porque es imposible dar cabida a tal cantidad de gente haciendo peticiones. Era un tema importante que como hablábamos de GPU y esta semana justo estaba en esto, para que tengáis el conocimiento. MIGUEL BURGUETE Muy bien. Vale, pues nada, dentro de los tipos de aplicación de la inteligencia artificial y de las 2 principales tecnologías que forman la inteligencia artificial, el machine learning y el deep learning, tenemos todo lo que son, no tecnologías, sino tipo de aplicaciones, divididas en diferentes ramificaciones, ¿vale? Como sabéis, tenemos todo lo que es data analytics, ¿vale? Centrado en análisis predictivo. ¿Habéis tocado, habéis visto series temporales? Sí, ¿habéis trabajado con series temporales? ¿Habéis visto modelos de series temporales con la asignatura machine learning? Esto es tremendamente importante. O sea, las series temporales, ¿vale? Es el modo más adecuado o, me atrevería a decir, correcto de poder trabajar con modelos de análisis predictivo en, por ejemplo, en entornos de producción, pero es que también no solo en entornos de producción industrial, que es decir, lo que hablamos ahora a nivel medioambiental, a nivel de medioambiental, si quieres predecir ciertos tipos de condiciones, tienes que historizar un montón de variables en configuración de series temporales. Si no estás vendido, las series temporales son el muestreo continuo, clave, valor, timestamp. Esto es muy importante en el machine learning, ¿eh? Procesar luego el modelo cuando tienes los datos en clave, valor y timestamp. Y hay modelos concretos como LIME y demás. ¿Habéis visto LIME? Algo de míga concreta de procesadores de series temporales. Pero, bueno, esto ya son temas teóricos de machine learning que tampoco quiero entrar. Pero sí que, al menos, si no habéis visto series temporales, deciros que a nivel real del mercado de la inteligencia artificial para poner sistemas en producción, darle un ojo al trabajo de machine learning con series temporales. ¿No habéis visto esto en? A mí me suena que sí. ¿Evito o Evito? Vicente. Vicente, hablo de esto. Héctor. Vale, sí, sí, sí, sí. Yo lo vi porque me dije, de hecho, mi TFM es básicamente tuve que usar series temporales. Puedes hacer series temporales. O sea, muy bien. Yo viví la carrera, pero más a nivel de econometría. Pues, esto es el modo de los más adecuados de preparar los datos para que luego pueda ser más eficiente o toda la fase de entrenamiento realmente llegue a buen puerto. Luego tenemos toda la parte de NLP. Súper explotada hoy en día con todos los últimos avances. Principalmente proporcionados por, pues, obviamente toda la fase de clustering y demás. Pero ahora todo lo que están moviendo a nivel de algorítmicos a veces son los transformers, ¿vale? Las arquitecturas de redes de transformers, que son las principales culpables de todo este gran crecimiento que estamos teniendo. Luego ya pasamos a los sistemas speech-to-text y text-to-speech que ven muy de la mano con los sistemas de NLP, como sabéis. Y luego, pues, toda la parte, pues, como por ejemplo planificación y optimización, que es directamente a la mano de los sistemas de simulación que os estaba contando yo. Toda la parte de robótica y ya luego la parte de visión, ¿vale? Visión artificial. Entonces. Perdona, ¿te puedo interrumpir? Sí, por supuesto. Dime. Sí, mira. A ver, ahí tengo la cámara. Hola. Lo que pasa es que me cuentes un poquito más sobre qué se hace en NLP y speech en la industria. Porque esa es como mi área de especialidad. Y yo he trabajado para área biomédica y más que nada industrias que tienen que ver con marketing. Entonces, en industria no sé cómo están usando el NLP o la voz. Entonces, si pudieras decir 2 o 3 cositas más que me pudiera orientar para ver si puedo también ofrecer servicio en esa área. Muy bien, muy bien. Claro que sí. Pues, muy buena pregunta. A ver, en NLP, ay, mira, y antes estaba diciendo, cuando estaba diciendo de 2 departamentos y medio, en relación con lo que estaba diciendo ella, el y medio no lo he terminado de explicar. El y medio es, y ahora voy con tu pregunta, pero hay algo que sí que quiero explicaros sobre ese tema. Ya no tanto a nivel técnico, sino porque creo que es importante que lo sepa eso, o sea, también os proporciono valor en este aspecto, sino a nivel de negocio y a nivel empresarial. NLP es una tecnología muy, muy interesante, pero está teniendo tanto crecimiento y tanto boom a nivel comercial que a nivel de negocio a las empresas tecnológicas le está pasando factura. Les está pasando factura, quiero decir que se están muchas intentando meter, pero al momento que se ponen a plantear proyectos con clientes gordos con esto, un becario que ya está en la empresa cliente, a lo mejor la noche anterior haciendo pruebas con ChatGPT que ha sacado la nueva actualización, no está haciendo exactamente eso, pero está haciendo casi la mitad. Y de repente ese becario aparece en una reunión y dice, pero es que yo creo que pueda probar esto. No va a hacer lo mismo. Y el jefe coge y dice, pues, mira, voy a esperar a que lo haga el becario. Y luego ya os diré. Y eso no solo nos está pasando, nos está pasando a muchísimas empresas. Se sigue pidiendo, se sigue, obviamente, el mercado está por ahí. Pero a nivel comercial ya y a nivel de negocio empresarial, uf, en muchos casos está costando. Entonces, por eso digo, hubo una iniciativa dentro de Tivis ahí de montar el nuevo departamento de NLP. Finalmente lo paramos. Seguimos con los 2 verticales principales, Data Analytics y Computer Vision. Y ahora mismo NLP es transversal. O sea, son los 2 verticales. La estrategia adecuada. Exacto. Es transversal. Porque montar un vertical de NLP con todo lo que cuesta a nivel de arquitectura de la empresa y todo eso. Es que es muy, muy arriesgado. Yo he tenido proyectos con Ford Valencia, Mastodonticos de NLP, y de un día para otro se me han caído por pocha GPT. Sí. Sí, además es un día. Al principio, crecían mucho las startups como champiñones. Y se acaba de, pues, no proceso PDFs, al día siguiente, ya lo proceso. La mitad de las startups. De las startups a tomar por culo, sí, sí, sí. Es muy difícil competir, yo, antiguamente. Totalmente. Totalmente. Entonces, eso, por eso y eso en las reuniones generales de empresas que tenemos, pues, lo decimos, ¿no? Decimos, mira, tenemos un nuevo cliente, un nuevo, ha entrado un nuevo proyecto de NLP. Ahora llevamos varios. Perfecto. Y yo se lo digo, bueno, ya veremos si sigue así, si lo cogemos y lo creamos departamento, pero de momento seguimos a nivel transversal. Porque tengo gente interesada en la empresa, tiene conocimientos de NLP y le gustaría más estar en proyectos de NLP, pero tenemos que tener una visión no solo técnica, sino también a nivel de negocio. Yendo a tu pregunta concretamente, sí, efectivamente. Mira, en NLP hay cosas que se están haciendo muy interesantes en industria que se están empezando a hacer. Esto es algo también bastante novedoso. Se empezó principalmente utilizando NLP hace ya bastante tiempo, principalmente en formación. En formación, muy ligada, iba de la mano con los sistemas de realidad aumentada, ¿vale? En formación, ¿vale? Como sabéis, pues eran principalmente, pues, sistemas donde te ponían las gafas de realidad aumentada, en los cuales también podías interactuar con NLP con, por ejemplo, los pasos que tenías que hacer para hacer una reparación de una máquina. Formación de riesgo laboral también se utilizaba. Formación de PRL. De trata técnico, así, para empezar, sí, para empezar. Entonces, ahí es como cuando se empezó a utilizar el NLP a nivel industrial, se utilizó dando esos pasos. Formación, PRL, etcétera, etcétera. Como digo, muy de la mano con la realidad aumentada. Es que tengo mucha relación con una de las principales empresas de realidad aumentada de España, que están en San Sebastián. Se llama Innovae. Innovae, ¿vale? Realizamos proyectos con ellos y tal. Son muy, muy, muy buenos. Trabajo mucho con Airbus y demás. Y están mucho en eso. Formación, PRL y demás. Entonces, empezó así. Y ahora ya estamos desarrollando nuevos sistemas ya basados en NLP y LLMs, principalmente para 2 cosas. Estamos en construcción y en automoción. Un sistema muy interesante es, hay versiones de las librerías de Yama, las conocéis, ¿no? Yama Index y demás, lo conocéis algunos, que tienen ya, tienen funcionalidades directas de Text-to-SQL. ¿Las habéis tocado? Eso es la transformación de la interpretación del lenguaje natural a una transformación, a un suite de queries SQL. Un suite, un conjunto, ¿eh? Ese conjunto luego se ejecuta contra las instancias de las bases de datos. Se generan unas respuestas y esa respuesta, a su vez, vuelve a ser transformada en lenguaje natural. Eso es tremendamente útil. O sea, está teniendo una tirada brutal en industria. Eso lo estamos haciendo en alimentación y también en construcción. ¿Qué te permite? Poder hablar directamente con las bases de datos. Es tan sencillo como eso. Hablar con las bases de datos. No te hace falta ningún tipo de conocimiento de SQL. Obviamente, también hay fases. En primer lugar, tienes que preguntar de una forma, luego de otra y el sistema va aprendiendo. Pero, básicamente, es eso. Entonces, eso es una de las cosas que se está utilizando. Y, luego, todo eso se está enlazando con lo que es más de conocimiento común, que es el tema documental. Vosotros sabéis perfectamente que ahora mismo hacéis CPT. Cogeis un contrato en PDF, se lo subís, lo procesa, le dice, dime el presupuesto del contrato que hay para la obra del mes pasado, no sé qué, y te lo va a decir. Lo que estamos haciendo es unir esos 2 tipos de procesamiento. El procesamiento a nivel documental con el procesamiento a nivel de SQL. Y estamos generando una potencia muy, muy interesante. Concretamente, ahora ya os estoy diciendo temas, por ejemplo, a nivel del sector de la construcción. Estamos con una gran consultora en el País Vasco, la cual tiene grandes bases de datos de todo su histórico de obras, hacen las edificaciones públicas y demás, de todos los contratos, que son páginas y páginas y páginas, pero luego tienen un montón de bases de datos de el consumo de materia prima, de productividad, de las subcontratas, de los trabajadores, de los costes, de todo en bases de datos. Si montas estos sistemas de NLP, texto SQL y consulta documental, a partir de ahí puedes decirle que su contrata fue más eficiente en las obras de tipo residencial durante el trimestre pasado, cuando cambiamos el tipo de hormigón. Ojo. Sí, perdón. No, Chava, eso es su proyecto final, es el trabajo final de máster, que es parecido, pero en recursos humanos. Ahora, que esto es más potente, porque lo que está hablando, Manu, en este caso, claro, al final es, antes esto lo hacía un informático, ya entre las entidades de SQL. O varios. Y también hay que llamar, es que esto lo cuentan los clientes. Sí, sí, claro. Hay que poner reuniones con departamentos, traer a los especialistas de cada departamento, luego que venga un informático. Pero esto donde hay que mirarlo, no sé, ¿en qué tabla está? No tengo ni idea. Hay que preguntárselo mañana porque hoy no está Pedro. Y al final, te tirabas varios días con un montón de personas y un montón de tiempo para obtener la respuesta. ¿Lo puede obtener el humano, la respuesta? Sí. ¿Cuánto tiempo, recurso y dinero hemos dedicado a obtener esa respuesta? Y si cambias un poquito, que ya no vives por año, y lo quieres dar otra vez, ahí está el problema ya. Y eso sí está, Chava, eso es un punto. Y eso es una punta más. Porque, digo, Chava, me lo cubro con los cerebros. Aquí es la parte del culo. Pero, por otro lado, no todo da el hecho de contar, ¿no? Pero, en este caso de uso, es muy potente. Es muy potente. Nosotros tenemos un proyecto financiado por la SPI. Hoy hablábamos un poco de las cosas que me pedías antes. Sí. La SPI es que el organismo de financiación pública a la investigación de un gobierno bajo. Si estáis interesados, o sea, si montáis empresas o trabajáis para empresas y estáis en ciertos departamentos también de innovación y demás, y tenéis proyectos en País Vasco, SPRI, tal cual, como SPRI, os interesa. ¿Por qué os digo esto? Porque el gobierno vasco a nivel industrial, el País Vasco, tiene el mayor tejido industrial de España. Y son los que más dinero ponen para inteligencia artificial, innovación, tecnología. Yo llevo muchos proyectos por eso. Y tienes que tener sede allí o tienes a alguien. Correcto, correcto. Y también está trabajando para allá. Y es complicada la cosa. Tienes que tener sede si tú eres socio del consorcio que presentas a la SPRI. Pero si va como subcontratado, no te hace falta tener sede. Vale, vale. Claro. Yo lo que he hecho es liar un poco, camelar a la constructora para que se presenten indicando que van conmigo, pero ya no aparezco como socio, aparezco como subcontratado y ganar el proyecto. Y es esto que os estoy diciendo. Nosotros con ellos estamos desarrollando una plataforma. Tengo por aquí, a lo mejor, si me da tiempo, una plataforma de control inteligente de todo el mundo. proceso de obra de las edificaciones que hacen, que tiene un conjunto, tiene toda la arquitectura web, la tenemos en Azure, toda la arquitectura web y tenemos un conjunto de modelos de análisis predictivo de predicción, de predicciones de desviaciones de cuántos se están gastando en la obra, si se les va, si el mes que viene se les va a ir todos los costes de materias primas, desviaciones en las desviaciones en las fechas de obra, desviaciones en las certificaciones de cada material, todo un conjunto de modelos de análisis predictivo. Efectivamente, es predictivo, en función de lo que está pasando aquí, en función del histórico y de la fotografía general te estoy prediciendo el futuro, eso es lo que tenemos y el proyecto nuevo ahora que nos financia la ESPRI del gobierno vasco es meter estos dos módulos de NLP, a nivel de las bases de datos y a nivel de la gestión documental de los contratos. Y esto ya es curiosidad aún más de detalle, que no sé si me lo puedas decir, es en esas predicciones, porque ahora tú haces una predicción, ¿qué porcentaje de aciertos hay? ¿De qué responsabilidad tiene el sistema? Son dos cosas distintas, son dos cosas distintas, no voy a hablar de la responsabilidad, para mí es, eso es muy fácil de saber, es decir, tú me has hecho la predicción de que el mes que viene voy a tener un desvío del 50% del presupuesto y cuando pasa el mes que viene, miro para atrás y digo, me dijiste un 50% y yo no he hecho nada, porque no he podido por lo que seas y he tenido una desviación del 100%, que me he gastado el doble, ¿me explico? Yo no he hecho nada, ¿a qué te refieres? Que él iba a hacer algo y no ha podido hacerlo. No, no, no he hecho nada, es decir, que me he pasado por el forro de tu predicción y realmente no se ha cumplido, ¿me estoy explicando? ¿Qué quiere decir? Que ha pasado el tiempo y no se ha cumplido la predicción. Exactamente. Eso se llama falsión positiva. ¿Y qué porcentaje de aciertos en predicciones hay? Esa es la predicción que se saca cuando ya hemos finalizado las etapas de validación cruzada en Machine Learning. Tú sacas una precisión que es válida a nivel matemático y científico del modelo de análisis predictivo. Esa precisión te la tiene que validar tanto el científico de datos como el cliente. ¿Vale? Que conoces un médico y dices, vale, esta precisión me es suficiente para ponerles con producción. Luego, cuando tú implantas eso y ya viene la realidad, pues llega la realidad y a lo mejor no se cumple la predicción, pues se llama falso positivo. O sea, si falla, si falla, hay dos estrategias. Ver por qué ha fallado, ¿vale? Que en muchos casos es así, sobre todo a nivel de cuando es una obra. Lo que ocurre es que habían planificadas unas cosas en las cuadrillas de las subcontratas que tenían que entrar a trabajar. Que el martes siguiente tenían que abrir los fontaneros con las tuberías de no sé qué y solo llegaron a la mitad de las tuberías que tendrían que haber llegado. Pues lo que han pasado son cosas en el camino que han hecho que la predicción de antes no se cumpliera. ¿Pero por qué? Porque no podemos hacer magia. Lo que no podemos saber es que la semana siguiente el jefe de las subcontratas se iba a emborrachar, al día siguiente no iba a ir al trabajo y como no iba a ir, no iba a ejecutar el pedido de materia prima de las tuberías de la obra. ¿Sabes lo que te quiero decir? Gregorio tiene la mano levantada, pero solo una cosa. Yo lo que me refería es, claro, si a mí me haces una predicción, vas a tener un accidente pasando por esta calle, yo no paso por esa calle, con lo cual nunca sabrás si la predicción se ha cumplido o no. Eso me refería, pasándome, diré, bueno, pues los resultados han sido mejores de lo esperado, porque tú has hecho una predicción, pero yo no sé el nivel de acierto, porque yo cambio mis condiciones en base a tu predicción. ¿Me estoy explicando ahora? Por eso veo difícil el medir los aciertos o errores de esa predicción. Ya, ya, ya. Sí, sí, ya te entiendo. Yo como empresario que me vienes y me dices, mira, yo te voy a predecir esto y digo, ah, genial. Esa sería mi pregunta. ¿Cuánto acertamos? Realmente, cuando es un proceso, insisto, que depende en cierto porcentaje del humano, es que, ¿cuánto acertamos? Es que es difícil saberlo. Claro, por eso... ¿Qué pasa? En otro tipo de sector, cuando lo controla un autómata, un robot o un sistema automatizado, ahí sí, ahí sí que puedes saber cuánto aciertas. Sí, un poco, bueno, para aportar en la discusión, lo que pasa es que cuando haces un modelo, bien sea, digamos, de este tipo de modelos de machine learning, en donde un poco, digamos, quizás, podrían ser de pronto de caja negra, un modelo, digamos, clásico de estadística, tú tienes unas probabilidades. Esas probabilidades se mantienen si se tiene algo que llamar godicidad, es decir, que las condiciones en las cuales tú mediste se mantienen. Obviamente, si hay un terremoto o algo, digamos, impredecible, pues no hay forma de anticipar este tipo de cosas. Entonces, digamos que las métricas que uno evalúa quizás son dentro de muestra y uno dice, bueno, yo tengo un porcentaje cierto que es del 95%. Eso quiere decir que cada 100 escenarios, en 95 va a pasar lo que yo te pronostico. En 5, no. Y eso es absolutamente normal. Es decir, no porque yo te diga que vas a ser exitoso o que vas a vender un producto, se vende. Coca-Cola también lanza, digamos, productos que finalmente no le gustan a las personas. Y eso lo tiene que tener en cuenta la persona que toma la decisión. Ningún modelo te da un 100% confiabilidad, de ningún tipo. Y es un poco lo que estabas exponiendo, que decías, bueno, yo tengo la foto y miro el panorama general, pues obviamente yo puedo decirte que con una probabilidad de un cierto tanto, pues tú tienes este mejor escenario y con eso tomas la decisión asumiendo un riesgo. Y es un poco de cómo se toma la decisión. Totalmente de acuerdo. Pero en función de la tipología de proceso, podrás ceñirte más a la predicción o menos, en función del porcentaje de acción humana que haya. Y esto principalmente cuando son sistemas automatizados, como digo, se hace en las fases de validación finales del modelo, principalmente. Entonces, bueno, volviendo un poco a la pregunta de la compañera, esos son dos sistemas muy inteligentes, muy inteligentes, perdón, inteligentes, muy interesantes de NLP en la industria. Espero que te haya servido. Sí, gracias. Yo te quiero interrumpir un poquito. Ando más lenta hoy día, por eso es que no soy tan óptima. Pero en la conversación de lo que estaban hablando sobre el tema de las métricas, yo no sé si aportaron, pero un poco consulta. Va en el sentido de que, claro, uno puede llegar a ciertas métricas y si el cliente quiere que sean mucho más asertivas, por decirlo de alguna forma, bueno, uno podrá el tiempo que signifique entrenar un modelo para que tenga obviamente una probabilidad más cercana a lo que busca. Pero yo lo que me pregunto siempre es porque uno llega, entrena el modelo, pero claro, en local y en tu fase de entrenamiento llega una probabilidad súper fantástica. Pero cuando despliegas, cuando necesitas ponerlo ya en producción, claramente eso se degrada. ¿Cómo lo manejan ahí en el caso de ustedes? ¿Cómo se llega a entregar ese porcentaje de pérdida que se va a entregar? Que ya es casi, o sea, es como algo que no se puede medir antes. O sea, ya lo tienes que meter en la máquina, en producción, para saber efectivamente cuánto es lo que te va a rendir. Entonces, me parece muy buena apreciación y es totalmente real. Quiero decir, tú cuando estás trabajando en la fase de entrenamiento de los primeros modelos, no estás trabajando en todo el pipeline de ejecución del sistema de producción. Esa es una realidad. Cuando trabaja el equipo de desarrollo, el equipo de ciencia de datos, está trabajando en sus ordenadores, en sus ordenadores y en nuestros servidores de machine learning que están lanzando a entrenar ahí, pero no están entrenándolo en el cloud del cliente o en los PCs del cliente que tienen los sistemas de integración de datos, de adquisición, de muestreo. Están leyendo de los controladores de máquina, de los PLCs y todo esto. Cuando tú ya has entrenado, digamos, en los servidores de machine learning, ya has entrenado el primer modelo, lo que tienes que hacer después es, cuando ya has desarrollado toda la arquitectura de integración de ejecución en el cliente, lo que tienes que hacer es colocar ese modelo ahí dentro, el modelo que habías desarrollado. Y cuando lo colocas, ese modelo se pone a trabajar en un todo, o sea, en un conjunto de diferentes módulos que tienen que ser solidarios los unos con los otros. Entonces, hay un sistema de integración, de historización, de ejecución y de control de dashboarding y de alarmas. Esos, digamos, son todos los módulos. ¿Qué ocurre? Que, sobre todo, en el primero, en el sistema de integración, ocurren, como dicen los chavales ahora, ocurren cositas, pasan cositas, ¿vale? ¿Y qué cositas pasan? Pues, pasan cositas que el comportamiento que están teniendo los datos en el origen, en la sensórica intrínseca que lleva la máquina y que luego se visualizan en el PLC, en el automata de gobierno de la máquina, empiezan a generar patrones de comportamientos que empiezan a ser, a lo mejor, ligeramente diferentes a los que tuvo el data set de entrenamiento que entrenó el científico de datos en la oficina. Esa es una cosa que ocurre. ¿Por qué? Porque es imposible tener toda la fotografía de todos los patrones de comportamiento que puede tener una máquina en producción, ¿vale? Entonces, empiezan a pasar cosas y empiezan a pasar lo que se conocen como derivas en las inferencias. Empiezan a pasar ciertas derivas. A partir de ahí, lo que se hace es coger, cuando ya tienes todo el pipeline montado y ese sistema de integración, son nuevos entrenamientos para hacer un, digamos, un fine tuning, que se conoce en machine learning, de ese modelo que previamente habías entrenado, con todo el pipeline de ejecución ya completo. Vamos a seguir. Bueno, estas son cosas que cuento también en clase. Vamos a seguir un poquito. ¿Por qué se aplica la inteligencia artificial a industria? Hay diferentes tipos de motivos. Los principales es, ¿cuáles son los objetivos de aplicar inteligencia artificial a la industria? En primer lugar, procesos de producción ineficientes. ¿Qué problemas hay? Alta tasa de productos no OK, productos con defecto, elevados trabajos de mantenimiento. ¿Por qué? Porque las máquinas se paran, se averían. Cuando una máquina se avería, no puede producir y empieza a producir la regla esta de los miles de euros cada minuto. Alto desperdicio de materias primas, bajas velocidades de producción, etcétera, etcétera. ¿Qué ocurre también? ¿Dónde estamos aplicando mucha industria? O sea, ¿a qué dirigimos los modelos de inteligencia artificial? En muchos casos, no a procesos de producción ineficientes, sino a pérdidas en costes energéticos. Eso también es muy importante. Hay una orientación muy clara a que tengamos pérdidas en costes energéticos. Cuando hay procesos muy distribuidos, motores, maquinaria pesada o sistemas de abastecimiento energético. Aquí os voy a contar un ejemplo sobre sistemas, por ejemplo, en EDAS. ¿Sabéis lo que son las EDAS? Las sedas son las estaciones de depuración de agua. Las estaciones de depuración de agua, ahí la mayor parte de líneas de investigación en Inteligencia Artificial no van ligadas a trabajos, sí que pueden ir ligadas a trabajos de mantenimiento, pues por ejemplo motores de bombeo, motores de accionamiento de los lodos y demás. Pero donde está el nicho de negocio a nivel de Inteligencia Artificial es aquí, es en los costes energéticos. Las sedas son grandes consumidoras energéticas y de costes energéticos. Entonces ahí, por ejemplo, nosotros acabamos de finalizar un proyecto con gobierno central de investigación en el cual hemos desarrollado un sistema de simulación que os comentaba antes, de virtualización, que te permite garantizar el output de la producción de la planta depuradora de agua, de todo lo que tiene que limpiar, por decir así, todo el agua que entra, pero minimizar los consumos energéticos asociados. Entonces, toda esa minimización de consumos energéticos lo que hace es que en tiempo real todas las líneas de producción están comportándose de forma nominal en la producción pero está gastando mucha menos energía de la que tiene que gastar. Lo que está pasando ahí básicamente es que predice el precio de la energía, predice las condiciones climatológicas, entonces sabe las plagas solares cuánta radiación del sol van a consumir, el motor de cogeneración sabe cuánto biogás está generando. Con todas esas condiciones lo que hace es reorganizar el proceso propio de la EDA, sacar órdenes de actuación, cada 15 minutos los estamos sacando para que modifiquen los parámetros de planta, garantizan el output de la producción pero al final del día te has ahorrado entre un 16 y un 19% de consumos energéticos. ¿Os imagináis el impacto a nivel económico que está generando eso? Es brutal. Entonces, las pérdidas en costes energéticos es un nicho muy importante de la aplicación de la inteligencia artificial hoy en día en ese sector industrial. Luego lo que se generan con paradas no planificadas, todo lo que son grandes averías que generan las paradas de producción y luego todos los fallos críticos. A nivel de sistemas de aplicación, ya en todo lo que venimos hablando en esta masterclass hemos comentado ya, si no todos, la mayoría. Esto se aplica en más ámbitos, pero estos son los principales, los que mayor línea de negocio están teniendo hoy en día en la industria con inteligencia artificial. Robótica guiada, inicialmente la robótica se hacía con, me acuerdo, con fotocélulas. Posicionabas el robot, porque recordad que yo empecé programando robots, posicionabas el robot en un sitio y según la fotocélula te decía cuánto te podías acercar al objeto y ya está. Luego se le empezó a poner cámaras de visión artificial para darle ojos, pero lo que hacía era poner una cámara y la fotocélula. Con una cámara obtenías dos dimensiones, X e Y. Es una cámara, es una matriz de dos dimensiones y luego dónde obtenías la profundidad, o sea la Z con la fotocélula. El siguiente paso de la robótica guiada que fue pasar a la estereovisión. Os habló Xavi de Javier, de estereovisión, en su ponencia. Claro, pasar a la estereovisión y es lo que todas las empresas de visión, nosotros, utilizan, la estereovisión. ¿Qué es la estereovisión? Los ojos humanos. Nosotros vemos en estéreo. En distintas cámaras, en la posición cada una de las cámaras que las tenías ahí colocadas. Claro, nosotros vemos en estéreo. ¿Por qué vemos en estéreo? Porque nosotros, lo primero que recibe nuestro cerebro es una imagen de dos dimensiones. Pero luego, solo recibe dos dimensiones, pero luego el cerebro calcula la tercera dimensión. profundidad. Ese es el motivo por el cual, si hacemos así, yo ya no tengo tan claro a qué distancia está el portátil. Porque ya nuestro cerebro no puede calcular la profundidad. Y, entonces, a partir de ahí, pues, sale, como digo, la robótica guiada con estilo de visión. Ahora ya guiada directamente con rayes neuronales y una sola cámara. Directamente te permite ahorrarte la cámara y calcular el suelo a la profundidad por reconocimiento de patrones con restricciones convolucionales. Luego, sistemas de visión deep learning de control de calidad. Muchos en alimentación, en autoemoción y demás. Hay un montón. Sistemas de eficiencia energética, como os comentaba. He puesto un ejemplo de una planta de agua, como os decía. Optimización de cadena de suministro. A nivel portuario, hay muchísimas líneas de negocio y de trabajo en optimización de cadena de suministro. Autoridad Portuaria Valencia está también financiando muchos proyectos en este sentido. Sistemas de simulación de procesos, como os decía. Y, luego, análisis predictivo. Este es uno de los que mayor crecimiento está teniendo uno de los cores de negocio de Tilisai y que también mayor financiación están dando las administraciones públicas, la análisis predictiva. Perdón, una cosa. De momento hacemos el descanso a las 7. ¿Queríais la parada para que también, a lo mejor, vale la pena que acabes este trozo, como tú te veas? Porque yo no sé que viene a continuación, pero. Digamos, sí. Porque te calculas un poco los tiempos, ¿vale? Sí, perfecto. Voy a ponerle dinerito a la plaza de, bueno, a la zona azul. Ahí es donde he dicho yo que aparques, ¿no? ¿Os parece bien, no, hacer la parada como siempre en torno a las 7? Normalmente, ¿cuánto es la parada? 20 minutos, nos pasamos un poquito más. Bien. Es que nuestra delegada de clase, Jenny, ¿no? ¿Qué decías? Ahí la delegada dijo que estaba bien, que a las 7, ¿no? Delegada en hechos nomás, pero, bueno, como se dice, en terreno, en terreno. Sí, 20 minutos, pero media hora hoy en día que estamos terminando, tampoco es malo. Muy bien, vale. ¿Os parece? Lo digo porque yo tengo, en fin, tengo un compromiso, tengo como a las 8 tengo que salir. ¿Os parece que hacemos la parada cortita? Sí, vale. Así digamos. Tengo 10 minutos, un piti-rati y seguimos, ¿os parece bien? Sí, seguimos. Y salimos antes que nos viene bien a todos. Vale. Perfecto. Pues, eh. Yo si os queréis quedar un rato más, tengo también para daros alguna cosilla, ¿eh? Pero, si no, marchamos. Vale, entonces, a las 7, ¿no? ¿Lo hacemos? ¿Sí? Venga, perfecto. Machine learning. La niña bonita, ¿vale? De la inteligencia artificial y donde salió todo. ¿Qué fases son necesarias para la implantación de un sistema de machine learning? Estas son, un poco, las fases que recomiendan los libros para implantar sistemas de machine learning en producción. Las habéis visto, ¿no? Habéis trabajado con esto, habéis visto la asignatura de machine learning. Esto ya os suena, ¿no? Parte de acceso al dato, más la parte de analítica, pero es más la parte de preprocesado, las fases de EDA, todas las fases de EDA. No la batería, ¿eh? Ah, sí. Pues, ya tengo que arreglar aquí. Las fases de EDA, ¿las habéis visto? Entre la sucesada y todo esto. Ellos son unos cracks y unas cracks. Claro que sí. Pues. Eso, obviamente, es necesario, ¿vale?, por toda la parte de los científicos de datos. Esa fase de preprocesado y demás. Luego la parte de desarrollo. Y luego ya se hace el deploy para hacer toda la plataforma web que ponemos ya directamente para ponerlo. Y luego también dispositivos embebidos y demás, como estábamos comentando también antes. ¿Qué ocurre todo esto? Que hay algo que los libros no dicen y es tremendamente importante. Yo os lo decía al principio de la ponencia. Aquí no hay enchufe, ¿no? Sí, ahí había una estupenda. Ah, aquí está el puente. Está tapado, ¿eh? Menos mal que tengo visión artificial. Me lo había guardado. ¿Qué es lo que los libros no dicen? De todo esto, porque además me decís que habéis visto esto en la clase de Machine Learning. Pero, insisto, y esto os lo decía al principio de la ponencia, Ernesto también lo ha remarcado después. Hay algo que los libros no dicen y que es tremendamente importante. Y es que yo he visto también a muchas empresas que han competido conmigo en programas de Open Innovation o en proyectos privados y que han competido conmigo y que han sacado mucho músculo. Hostia, mirad, que legión de científicos de datos tengo, de ingenieros de Machine Learning, que cuántos doctores te estoy poniendo aquí en esta reunión. ¿Qué ocurre? Que mucha gente no se centra, se centra solo en esa, digamos, en esa vertiente más de inteligencia artificial y se centra poco en esto. Ellos dicen, sí, sí, por supuesto, es importante. Cuando llega a la práctica, le dedican poco tiempo a esto. ¿Para qué? ¿Para qué? Al conocimiento, claro, el conocimiento del proceso que van a optimizar. No tiene nada que ver, y os lo aseguro, un sistema de inyección, una inyectora, a nivel de los datos del proceso, cómo se comportan o cómo vas a llegar a ellos, a un sistema de mecanizado, a un sistema de embotellado, a un sistema de atornillado, a un sistema de soldado, a un sistema de bombeo. Es tremendamente diferente. Los sistemas de control, los canales de datos, los sistemas de mostreo, es tremendamente diferente. Entonces, eso es clave, que os centréis primero en el conocimiento del proceso que vais a optimizar. Porque el conocimiento a nivel de machine learning lo tenéis, bueno, por eso o estáis en una empresa de machine learning o estáis subcontratando el servicio. Pero es tremendamente importante esto. ¿Te complemento algo ahí? Me surge a mí el tema también de que tanto como aprender el proceso, como lo están realizando en el momento, es también trabajar un poco la mentalidad de que es posible que para poder implementar todo este proceso con machine learning, inteligencia artificial, va a haber que cambiar el proceso. Y yo creo que ahí de repente hay como resistencia en la empresa, porque asume que la optimización es simplemente incorporar la tecnología y ya, ya está optimizado. Pero muchas veces tienes que cambiar el proceso como se ha llevado antes, porque así como es llevado antes, es ineficiente y necesitas optimizar o necesitas automatizarlo. Entonces, va a tener que cambiar la forma en como siempre se ha realizado para que sea en forma óptima. Me parece perfecto tu comentario, porque es tal cual la realidad de lo que acabas de decir. Y además de cambiarlo, me ha gustado mucho lo que has dicho, que muchas veces la empresa y la inserción son reticentes. Hay algo que se dice mucho también en. en eventos y congresos de inteligencia artificial y de innovación que se hablan los gurús, los gurús estos, pero los gurús también se hacen llamar de otra forma, ¿sabéis cómo se hacen llamar? evangelizadores, ¿sabes? son evangelizadores de la ley. En inglés, evangelist. Tan cual, se hacen llamar evangelizadores, pero lo dicen también porque muchas veces es una labor de evangelizar a la propia empresa, de todo ello. Entonces, totalmente me parece muy acertado el comentario. Por lo cual, dicho esto y todo este conocimiento, pues tenemos que... Tenemos las fases de acceso a datos. ¿Cuántas tipologías de datos de entrada podemos tener? Montones. Estamos trabajando con un robot de seis ejes en una línea de evaluación. Estamos trabajando con un sistema de inyección de plástico. Estamos trabajando con un horno. Estamos trabajando con un sistema de audio, por ejemplo. Estamos en proyectos de investigación de audio, que lo que hacen es cosas tan curiosas como todo lo que es el vehículo eléctrico. Imaginaros la cantidad de conexiones eléctricas como se ha multiplicado en el vehículo. Esas conexiones eléctricas, como la propia palabra dice, conexiones, hay que conectarlas. Conectarlas es con un socket macho y hembra para conectarlo. El momento que tú das una conexión que hay que conectar, le das el margen a que eso no se haya conectado bien. Eso es súper importante en la industria. Entonces, ¿qué pasa? Hay proyectos de investigación, estamos en uno, que estamos controlando con inteligencia artificial la detección del sonido del clipado. El clip. Está muy muy chulo el proyecto. Es una pulsera que lleva el operario con un dispositivo aquí y tiene un micrófono de ultrasonidos aquí. El operario va conectando todas las conexiones eléctricas del coche. El sistema va detectando los clics a la frecuencia concreta de los clics de cada uno de los conectores. Todo esto se envía por Wi-Fi o por Bluetooth. No sé si era por Wi-Fi o por Bluetooth a un punto de acceso, un servidor de machine learning que estaba también en la línea. Y eso, estuvimos entrenando una serie de modelos que detectaban únicamente el clic de los conectores, ignorando de forma inteligente todo el ruido y todo el conjunto de sonidos que había en la línea de producción. Os podéis imaginar que es de la hostia. Desde el operario al lado, que está cantando Camela, a mil sonidos que ya son prácticamente igual que un clipado, desde mil sonidos mucho más cortos y agudos, a luego también los clipados del operario que está en la línea de al lado, que también se oye. Pues el modelo ha aprendido a detectar únicamente estos clics. Es una pasada. Y esto, si os fijáis, ya os lo digo de los datos de entrada. Son datos de entrada muy diferentes a los datos de procesos propios, por ejemplo, de un PLC. Son datos que cuando tú coges una frecuencia de onda, una forma de onda, ya tienes que aplicar transformadas de Fourier y demás. Cosas que en datos de series temporales no tienes que hacer. De todas maneras entiendo que te indicará que te ha saltado uno o que falta un clipado, pero no te indicará cuál. A menos que siempre lo hagan en el mismo orden. Yo me imagino un proceso de producción donde vas conectando. Me gusta mucho lo que estás diciendo porque tiene relación directa con lo que ha dicho la alumna hace un momento. Lo que hemos hecho, hemos modificado el proceso. diciendo ella. Para que esto pueda ser viable o que pueda llegar a tener las funcionalidades que está exigiendo en este caso Sport, que está exigiendo, yo le dije, vale, pues, si queréis esto, pues, dice, vale. Porque querían hacer justo lo que estás diciendo. No querían solo saber, la gente, para el coche en una estación y tiene que conectar, por ejemplo, 5 conexiones eléctricas de la batería, 5. No querían solo saber si alguna de las 5 se había quedado sin clipar, que eso ya está muy bien, porque detectan un problema gordo que puede haber. Si no querían saber de las 5 cuál era, ¿vale? Pues, yo le dije, perfecto. Puedo meterme también ahora en investigar el tipo de sonido de cada uno de no sé qué para decirte tal, digo, pero va a ser mucho más sencillo si al operario le dices que lo hagan a este orden. Ahí salta en el momento que dice eso. La gente está contando, primero, segundo, tercero. Y sabemos que el primero es el conector del BMS de cargador del coche. El segundo es el tal, pues, ya están clipificados. Y si falta el tercero, pues, ya sabes que el tercero que corresponde a este módulo es el que no ha conectado. Ahí lo que pasa es que también estamos añadiendo el margen de error del humano. Y si el operario no ha hecho el orden. Eso te digo, que al final eso es muy complicado. Pero, bueno, entonces, como os digo, la tipología de los datos de entrada es muy grande, por no hablar también, por ejemplo, de las nubes de puntos en visión artificial, etcétera, etcétera. Entonces, tipos de datos. Joder, es que voy a estar hablando aquí por estar hablando 3, 4 días de todo esto. Tipos de datos. Algo que ya os digo que en la teoría lo habéis podido ver de una cierta forma, pero luego tenéis que aterrizar en la realidad. La realidad es que tenéis que tratar los datos, ¿vale? Organizarlos y dividirlos de una forma muy concreta si queréis llegar luego a resultados viables a nivel de precisión en producción. ¿Cómo tenéis que organizar los datos? Principalmente en sistemas de análisis predictivo. Aquí no estoy hablando de visión, no estoy hablando de NLP, estoy hablando de sistemas de análisis predictivo en datos basados en series temporales, ¿vale? Hay 4 organizaciones principales en las que os tenéis que centrar. Tenéis que saber dividir entre lo que son los datos de proceso, contexto, aplicación y explotación. Todo esto ya os digo para, como os decía al principio, ya a nivel práctico para implantar modelos en producción. ¿Qué son los datos de proceso? Diciendo, digamos, dándoos esta pincelada, ¿os atreveréis a decir, hacer una división aproximada? ¿Qué sería proceso, contexto, aplicación y explotación? ¿Qué sería proceso? Me parece que es lo fácil. ¿Cuáles son los datos intrínsecos del operatorio que os está haciendo? El click que hace. Sí, podría ser el click. Pero quiero decir, por ejemplo, vamos, no, porque el click es el sistema. Es el sistema. En la portátil selectiva, sí. ¿La portátil selectiva, sí? Dicho sí. Que no puedo ayudar. Sí, no puedo ayudar. El sistema de detección de clickado con audio, efectivamente lo que pasa es que es una cosa muy, muy, muy concreta, ¿vale? Vamos ahora a no pensar en eso. Vamos a pensar en sistemas un poco más normales a nivel de análisis predictivo con IA, ¿vale? Lo que os estaba diciendo de predicción de calidad, predicción de averías. Leer datos de una máquina, que es lo que más se utiliza en inteligencia artificial. Te conectas con una máquina, gran máquina o línea de producción y empiezas a leer datos, un montón de datos. Los datos de proceso son los datos en los cuales estás midiendo el comportamiento de la máquina que está generando las operaciones de producción. Quiero decir, yo lo llamo a nivel mal dicho, es tomar la temperatura de la máquina. Ahí estás mirando, cuando está una máquina haciendo un proceso, variables de temperatura, variables neumáticas, variables eléctricas, variables de presión. Estás viendo, es como, y tiene muchas comparaciones con el sector médico. Cuando te ponen todos los selectores que te están midiendo, la presión, la sangre, cuánto, todo, ¿no? Pues, eso son los datos de proceso de una máquina en un sistema de análisis predictivo. Tiempos, temperaturas, caudales, todo esto, ¿vale? Para saber qué variables de vida está teniendo la máquina cuando está generando, por ejemplo, está fabricando una pieza, ¿vale? Esos son los datos de procesos. ¿Qué son los datos de contexto? Los datos de contexto son los datos que rodean a la máquina cuando está haciendo esa operación, pero no son propios de la propia máquina. Los datos de contexto son, por ejemplo, el operario que está delante de la máquina, que parece, ostia, el operario que pinta aquí en esta fiesta. Ostia, si os contara yo historietas de operarios incluso que de repente tiraban tornillos o no sé qué para que se pararan la línea porque no les había gustado un sistema que habían implantado porque les daban más trabajo. Entonces, lo hacían parar para que dirección dijera, es que esto me para demasiado la línea, lo quitamos de aquí. Y al operario le solucionaban más las vías. Por lo que decía antes la compañera, porque modificaba su proceso y les daba más trabajo. Pues, yo he visto operarios que saboteaban, tiraban tornillitos, cortaban la barrera y paraban la línea. Y se guiaba. Y se detectó al final que era un operario quien estaba haciendo eso. Hay operarios que se dan maño y son los que saben ajustar las máquinas y el resto no. Entonces, con ellos es más eficiente. Efectivamente. Ahí se habla de skills de operarios. Esto se utiliza mucho también en sistemas de GMAO, ¿vale? De mantenimiento industrial, los skills de los operarios, totalmente. Entonces, los datos de contexto, operarios. Por ejemplo, el turno. El turno de trabajo que decís, ¿qué pintará el turno? Hostia, pues, a lo mejor pinta. A lo mejor en el turno de noche hay unos patrones de comportamiento de la máquina o de calidad que no hay durante el turno de día. Porque por la noche, pues, la vida cambia, pasan otras cosas. Y, entonces, hay que tenerlo también en cuenta para identificar los patrones de comportamiento en los datos. O, por ejemplo, el nivel de pieza. ¿Qué tipo de piezas está fabricando cada momento? Todo esto son los datos de contexto. Los datos de aplicación. ¿Qué son los datos de aplicación? Los datos de aplicación en un modelo de machine learning, de análisis predictivo, son los datos que dictan el tipo de aplicación que va a tener el modelo. Quiero decir, ¿va a tener una aplicación de calidad? ¿Va a tener una aplicación de mantenimiento? ¿Va a tener una aplicación de disponibilidad de máquina? Esos son los datos que dictan el tipo de aplicación. ¿Y cuáles son? Unos datos que nos van a ayudar mucho. Los datos de etiquetado. ¿Por qué? Porque nosotros no etiquetamos con datos de proceso. Los datos de proceso no sirven para etiquetar. Los que sirven para etiquetar son los datos de aplicación. Cuando nosotros trabajamos con estrategias de algorítmica supervisada, normalmente enlazamos aplicación con proceso. Eso ahora os lo comentaré. Y luego tenemos los últimos, los datos de explotación. Esto es más sencillo. ¿Cuáles son los datos de explotación de un modelo de machine learning? ¿Qué es inferencia? Es la salida, la salida ya del modelo, los resultados. Y a partir de ahí se generan varios. No solo la inferencia, sino, por ejemplo, ¿qué hacemos con la inferencia? Pues muchas veces la comunicamos con un sistema de alertas. Sistema de alertas también genera resultados. Esos resultados también son datos de aplicación. Y todo eso, explotación, aplicación, contexto y proceso, hay que historizarlo todo. Normalmente con sistemas de big data que también han visto. ¿Son las 7? Sí. Chicos, tenemos que parar. ¿Paramos, pero, entonces, un minutillo solo? Sí, un poquito. Sí. Vale, perfecto. En 10 minutos los que estáis online, ¿vale? Sí, vale, iba a hacer una pregunta, le hago la vuelta. Vale, vale. Muy bien, muy bien. Muy felices, sí. Están pasando las preguntas. Ellos son muy aprovechados. Un saludo y nos vemos en el próximo video, ¡hasta la próxima! Subtítulos realizados por la comunidad de Amara.org Subtítulos realizados por la comunidad de Amara.org Subtítulos realizados por la comunidad de Amara.org Subtítulos realizados por la comunidad de Amara.org Subtítulos realizados por la comunidad de Amara.org Subtítulos realizados por la comunidad de Amara.org Dije, tiene que haber un módulo, además de todo el tema de Azure y tal, que eso también para mí era imprescindible. Tiene que haber un módulo que sea enfocado a la empresa y que la gente venga a solucionarlo. O sea, que venga gente y no es fácil buscarlo. Venía un tío de AMI súper potente de AWS, tenía un programa médico serio. Y hace dos semanas y hemos tenido que buscar un reemplazo, por eso te dije de cambiarlo, de tal, a ver cómo lo hacía para hacerle el Tetris. Y ahora viene, la semana que viene, viene una jueza. Una jueza especializada en temas de guía. Hablamos de ética. Viene de Canarias agredida a dar la clase. Y mañana viene una amiga. Bueno, tú la conociste, Isma, una chica rubia. Pues, viene a dar la clase de temas de la parte de testing. ¿En tu despedida? No. No. ¿Es de NTT? No, ¿no es eso? No, no, no es eso. Ella viene de Barcelona. ¿Y dónde la conociste? En el Infernos o Infernos o. Ah, en el Infernos, sí. En Infernos, ¿no? ¿Qué tal la? Infernos no. Se me he cruzado un poco. Bueno, y ahora hablemos de eso. Que fuera feliz. Sí, no, cerrar, cerrar, cerrar. Sí, me dijiste, bueno, pero es que no lo dijiste. Yo ya te lo había planificado y me he ido al pueblo. Pero, claro, lo dije también porque, claro. Subtítulos realizados por la comunidad de Amara.org Subtítulos realizados por la comunidad de Amara.org Subtítulos realizados por la comunidad de Amara.org Subtítulos realizados por la comunidad de Amara.org Subtítulos realizados por la comunidad de Amara.org Subtítulos realizados por la comunidad de Amara.org Subtítulos realizados por la comunidad de Amara.org Subtítulos realizados por la comunidad de Amara.org a esperar dos minutillos y empezamos vale vale justo iba a preguntar si había un partido no porque veía que hablaban y no escuchaba nada no bien bien bien estaba estamos hablando más de temas de videojuegos y de historias aunque sí sí no parezco es que la cámara es un vampiro no es que no es que la cama está ahí se va a parecer a pues nada dos minutillos y empezamos y si quieres lanzar la pregunta soy joana soy joana todo el mundo no había dicho antes que quería preguntar no no era yo mira mi consulta es porque cuando hablaste sobre el tema de contexto me llamó la atención porque justamente he escuchado mucho últimamente hablar del surgimiento del context engineering entonces me pregunté si tenía algo que ver con eso o no te lo digo más que nada porque yo siempre he trabajado en industria limpia o sea no en industrias físicas entonces he trabajado con temas de banco farmacéutica todo lo que a industrias creativas entonces educación pero yo así de industria de autos de operario yo de eso nada entonces no sé si es el mismo contexto el mismo el mismo concepto o no tiene nada que ver no no no es diferente es diferente en la línea con contexto ingeniería esto es una esto es a nivel de gestión además perdona joana joana esto es a nivel de gestión o sea esto es a nivel de gestión sí que lo hace el ingeniero de machine learning pero es digamos un trabajo de gestión que tiene que hacer previo para saber cómo tratar los datos a qué división de datos tiene que hacer ok no es tanto una tarea técnica sino es tanto una tarea más de gestión que tiene que hacer el propio ingeniero de machine learning de separar en diferentes bloques de datos proceso de contexto de aplicación y de explotación y con los de contexto pues pues también igual súper y lo otro que escuché es que dijiste algo de sensores y que se parecía al área médica que es como el área que si me gusta mucho entonces yo nunca he considerado sinceramente el área industrial pero cuando dijiste eso de que eso se parecía al área médica me llamó la atención que se está haciendo o son proyecciones o ya se están haciendo cosas concretas en temas de aplicar sensores en lo que tú decías que esto dijiste se parece como al área médica entonces esa parte específicamente claro en sensórica totalmente quiere decir igual que cuando hay cuando un paciente está hospitalizado que cómo está pues está en la cama y le están monitorizando un montón de variables vitales verdad un montón de cosas pegadas al cuerpo y están contratando la frecuencia nivel de oxígeno en sangre el la presión etcétera etcétera son sensores que están monitorizando las constantes vitales de la persona pues Eso es exactamente igual a cómo se muestran los datos de proceso de un sistema de producción industrial. Realmente estás monitorizando las variables vitales de la máquina. Obviamente no la frecuencia cardíaca porque no hay ningún corazón latiendo, pero lo que estás midiendo es, pues en vez de la frecuencia, estás mirando la temperatura a la que está girando el electrohusillo, estás mirando todas las variables, las canalizaciones neumáticas, estás poniendo un preso estato para medir la presión en cada punto, un caudalímetro. Es muy extrapolable esa medición de las variables de constantes vitales a nivel médico a el mostreo de los datos de proceso de una máquina. Genial, bueno, qué bueno que me dices porque yo todavía estoy tratando de dentro de las industrias de Valencia, como son tan distintas a lo que yo he hecho siempre, estoy tratando de ver por dónde entro o por dónde yo podría aportar. Y ya qué bueno que dices eso porque esa área me gusta mucho, todo lo que es robótica y sensores y análisis de todo eso sí. Lo que pasa es que a mí no me gusta ensuciarme, entonces yo no me imagino yéndome a la industria, así como irme a los polígonos, ni mucho menos. Muy gracioso eso. Sí, la verdad es que a nadie, muy sincero, a nadie nos gusta ensuciarnos. Tengo que decir que yo tengo algo de nostalgia de cuando yo programaba y cuando yo programaba además a pie de producción, ¿vale? Tengo algo de nostalgia. Era muy duro también, pero curte mucho y aprendes mucho, muchísimo, pero te tengo que decir que no, nadie, ahora que me oyen mi equipo de trabajo, son vamos, yo les llamo princesitas. No se ensucia nadie, ahí están en la oficina y desde casa también, trabajando, todos muy bien y no se ensucia nadie. Obviamente hay reuniones e instalaciones del cliente y a veces nos tenemos que desplazar ahí, pero para nada. El paradigma del programador a pie de línea de producción como se hacía antes. Bueno saberlo. Pues sí. ¿Tiene una pregunta compañero de abajo? Sí, un poco tenía la pregunta de cuando hablabas de las muestras, un poco como en lo que digamos trabajas tú, cómo se selecciona. Igual las muestras tienen un coste, ¿no? Es como que yo lo hago cada tanto y ya y también tiene un componente importante en estadística porque dependiendo de la muestra que tengas, tendrás también asociado a eso una confiabilidad. Es decir, entre más muestra tengas, más certeza tendrás de que lo que peredices es más parecido quizás a la realidad del proceso. Esa es una pregunta, ¿cómo determinar tamaños? ¿Cada cuánto lo hacen? ¿Cómo lo hacen en la práctica? Porque igual es un proceso industrial y esto también tiene que ver, como te digo, con costos y con capacidad de poderlo hacer. Y otra es un poco cuando yo veo que la gente agarra variables y me parece interesante que dijiste siempre como que se enfoca mucho en voy a simplemente meto eso en un modelo y alguna cosa sale y eso me pronostica algo que va a pasar y pues evidentemente no es así, pero pues como que todo el mundo lo toma por ese lado. ¿Es algo importante? ¿Qué variables vas a introducir? ¿Cómo hacen para seleccionar, en la práctica, cómo hacen ustedes para seleccionar? ¿Qué variables van a poner allí? Porque también son tiempos de procesamiento, ¿no? ¿Cuáles variables sí y cuáles variables no? Si llega a un consenso o mira, van explorando. ¿Cómo lo hacen? Realmente, mira, antes justo hace, cuando hemos hecho el descanso, lo estábamos comentando Ernesto y yo, que hacéis preguntas muy buenas. La verdad que esta también es una pregunta muy acertada. En primer lugar, a nivel de tiempos, ¿no? Es que preguntabas ¿cuánto tiempo de histórico. Una parte de tu pregunta iba por ahí. ¿Cuánto tiempo de histórico? Pues a ver, no sé si la palabra es lamentablemente, pero quiero decir, al fin y al cabo, estamos desarrollando cosas que son muy novedosas. Todo esto que estoy comentando son cosas muy disruptivas, que no está muy estandarizado todo. Hay cosas estandarizadas, pero estamos innovando. Entonces, aquí el conocimiento de qué cantidad de histórico y, sobre todo, la cantidad de histórico, lo que va a medir cuánto histórico tienes no es sólo el tiempo, sino es también, en ese tiempo, cuánto has metido ahí. O sea, no vale lo mismo estar muestreando un nivel de presión con un preso estato a un segundo, que medir una variable de corriente de un electrohusillo a 50 milisegundos. La cantidad de histórico de datos que te va a inyectar en el sistema Big Data va a ser completamente diferente. Entonces, eso en primer lugar es, te diría que es por experiencia, en la mayor parte de los procesos, o sea, por experiencia del equipo técnico. Cuando has trabajado, por ejemplo, con sistemas de atornillado, pues sabes que a cuánto tienes que muestrear la variable de par, a cuánto tienes que muestrear la variable de ángulo y a cuánto tienes que muestrear la variable de cota, que son las tres principales variables de los procesos de atornillado. Entonces, en base a eso, tú ya puedes hacer un cálculo correspondiente y decir, vale, pues con dos meses de histórico puedo empezar a entrenar mis primeros modelos de análisis predictivo. Y luego, en relación a tu segunda pregunta, ¿cómo seleccionamos las variables? Por ejemplo, te acabo de decir las tres principales variables de un proceso de atornillado. Claro, yo hace a lo mejor 10 años yo no sabía que eran esas variables, pero sí que soy un ingeniero de Machine Learning. Lo que pasa es que no sabía que eran esas variables. ¿Cómo las sabemos? Por dos principales razones. La primera, lo que te estaba comentando al principio, cuando empezamos a desarrollar toda la línea de negocio, insistí mucho en que hubiera gente de procesos industriales con el equipo de científicos de datos, ¿vale? Para que entre ellos hablaran y llegaran a un consenso de cómo integrar las variables, cómo adquirirlas y, sobre todo, cómo seleccionarlas. Es un poco lo que estás diciendo tú. Y luego también eso lo tenemos que ponderar con otra medida, que es, normalmente suelen ser los departamentos de mantenimiento de los clientes. Los departamentos de mantenimiento ahí tienes gente que lleva 35 años trabajando ahí, sabe todo cómo funciona, qué variables están manejando y demás. Y realmente ellos no saben de inteligencia artificial. Ellos tienen inteligencia natural, pero esa inteligencia natural a nosotros nos da mucha información, ¿vale? A nosotros nos lo dice. Entonces, cuando te sientas con Paco, que entra a la reunión con el palito de café en la boca, que lleva 35 años ahí, que no sabe, oye, inteligencia artificial y no sabe de qué le estás hablando, pero tú le empiezas a extraer información a ese Paco y entonces te dice las claves, que él intuye que van por ahí los tiros, pero tú coges eso y a partir de ahí montas su estrategia a nivel de Machine Learning. Es que iba por ahí, ¿no? Tu pregunta. Sí, sí, sí, me sorprendió. De la primera parte, pues, de la segunda totalmente de acuerdo, digamos que sí, yo soy estadístico y así pues he trabajado también un poco el tema de saber, pues, un poco de eso, porque tampoco sé todo y también trabajo con procesos que no domino, cosas y de la primera parte, pues, digamos que me sorprendió, por eso pregunto mucho, he preguntado mucho, porque digamos que si hay un área para determinar tamaños de muestra, digamos que uno, en estadística, hay un área que es el control de calidad y uno a veces, cuando necesita un tamaño muestra, que otras cosas, no esto que es mucho más grande, hace cálculo en los tamaños de muestras óptimos, como para lo mínimo necesario que uno necesita para no desperdiciar recursos. Entonces siempre pregunto porque no he encontrado una respuesta, tampoco he visto como áreas de investigación por ese lado, imagino que habrá pero desconozco. Tampoco digamos que habría un área de una buena oportunidad en ese ámbito porque si economizaría mucho recursos, quizás si yo muestreo más de lo que necesito, poco al margen de la experiencia que puedan tener las personas. Por eso preguntaba, muchas gracias, está genial la respuesta. Sí que hay, vamos a ver, sí que hay técnicas que se están utilizando para poder medir niveles de histórico. Hay metodologías de explainable, de explicabilidad, que sí que se están utilizando porque si os fijáis, cuando tú obtienes, cuando tú abres un modelo de Machine Learning, que básicamente son las técnicas de explainable, puedes obtener, por ejemplo, la relación de las variables más responsables en generar ciertas inferencias que son las que te interesan. Y cuando tienes eso, a partir de ahí, tú ya puedes tirar del hilo y ver, cuando tienes las variables, puedes ver también qué tiempos, o sea, quiero decir, puedes ir reconstruyendo tú la respuesta hacia atrás. Puedes ver qué tiempos de historización se tuvo en determinadas variables, en qué momentos la inferencia fue correcta y en qué momentos la inferencia no tuvo precisión. Ese conjunto de técnicas que se orquestran principalmente con modelos de explicabilidad, te permiten saber también el nivel de histórico que tienes que tener. Gracias. Nada, gracias a ti. Jenny, buenas. Vale, mira, quería comentarte algo y me lo recordé y me dio a preguntarte por lo que comentaba un poco Johanna, que me daba un poco de risa, sí, el tema de ese trabajo un poco industrial. Bueno, yo te comento que en mi caso yo trabajé en el ejército, entonces yo era oficial de material de guerra, logística, y claro, yo trabajé en maestranzas y a mí sí me gusta ese tema, la verdad. Yo trabajaba mucho con armamento, explosivos, vehículos, entonces la verdad es que era bastante sucio el trabajo, pero a mí me encantaba. Y después, ya cuando me salí, trabajé en una fábrica de cartón corrugado, entonces ahí a trabajar en la parte de distribución de productos, transporte y todo. ¿Y por qué saco a esto? Claro, en los tiempos en que yo lo hice puede explicarse de que fuera muy manual, pero en la segunda experiencia era una empresa logística de hartos recursos, digamos, una empresa grande en Chile, de uno de los consorcios más importantes en Chile, que es un oligopolio, o sea, son siete familias que se reparten en el país y era una de esas empresas. Y a lo que voy es que era muy manual el proceso, aunque muy bonito todo lo que lo que se realizaba en esa área. Te digo, logística a mí me gusta mucho. Entonces eso me hizo pensar en preguntarte también tu experiencia y lo que ustedes han hecho. ¿Han hecho, por ejemplo, proyectos relacionados con defensa? ¿Han podido entrar en esos rubros? Y si no, ¿en el área logística? Porque sé que aquí, particularmente en Valencia, me imagino que lo portuario es lo que lo debe llevar en temas de logística, pero claro, también están otras empresas que son de distribución de otros productos. Entonces, más o menos, a ver qué es la experiencia que tienen ustedes implementando ya este tipo de cosas. Si están como metiéndose de plano en esto, porque esas son como industrias que ya deberían estar, si no ya, es porque están atrasados. Totalmente, Jenny. Y reitero que aquí hay nivel, ¿eh? Aquí hay nivel, porque son preguntas muy buenas. En primer lugar, aquí hay una cosa que es tal cual. Valencia, a nivel logística, manda el puerto de Valencia. El puerto de Valencia ahora mismo es el segundo de España. después de Algeciras, ¿vale? Ahora mismo a nivel de importe export superó ya a Barcelona. Ha superado a Barcelona. Y Barcelona ha rabiado bastante por una serie de finanzas que, claro, ya van pivotando las financiaciones del gobierno y tal. Ya estamos en el número 2. Y aparte que Valencia es el puerto de Madrid y que ahora con la ampliación norte que, por si no lo sabéis, esto también a nivel de negocio, la autoridad portuaria de Valencia no responde al ayuntamiento. Es algo importante también a nivel de proyectos de innovación porque el ayuntamiento no quería la ampliación norte. Y han estado ahí de peleas, o sea, porque el puerto de Valencia decía, yo quiero coger toda esta área. Y el ayuntamiento decía, no puedes. Y el puerto decía, tú a mí no me dices lo que puedo o no puedo hacer, yo respondo a puertos del estado. Eso es otro tema. Política. Es política. Lo digo porque es política, pero al fin y al cabo la política nos toca a todos. A mí eso me ha tocado a nivel de negocio en mi empresa, implantación de sistemas y demás. Entonces, efectivamente, a nivel de logística, pues, por ejemplo, aquí en Valencia, la autoridad portuaria, todo esto, hay muchos proyectos que se están moviendo y sobre todo de optimización de cadena de suministro, ¿vale? Por supuesto. A nivel de defensa. A nivel de defensa ha pasado una cosa. Por eso es interesante también que lo preguntes. Y no viene por nosotros, viene derivado por un señor que se llama Donald Trump, que anunció hace bien poco que va a cortar el grifo. Y Europa se ha puesto nerviosa y, como sabéis, de hecho es noticia estos días con el tema del PIB, etcétera, etcétera. Pero antes de eso ya hay una circulación de los fondos Next Generation, que también Ernesto me pedía que hablara un poquito de esto. Los fondos Next Generation es la base por la cual se están financiando prácticamente el 80% o 90% de los proyectos de investigación en España actualmente, los fondos Next Generation. Vienen de Europa, pasan por el Ministerio de Innovación y el Ministerio de Innovación los distribuye a las comunidades. Y, como os decía, gobierno vasco es uno de los que más músculo tienen, ¿vale? Valencia estamos bien, pero gobierno vasco son los que más apuestan por eso. Entonces, en defensa ahora mismo se está inyectando muchísimo dinero a nivel de proyectos de convocatoria pública a través del CEDETI. ¿Sabéis aquí lo que es el CEDETI, chicos? El CEDETI es el Centro de Desarrollo Tecnológico Industrial. Creo que lo he dicho, creo que son las siglas, algo así, ¿vale? Es algo, si os vais a dedicar a inteligencia artificial y vais a tocarte más como de los que estoy hablando yo que seguro que tocaréis, tenéis que saber lo que es el CEDETI, ¿vale? Es el organismo dentro del Ministerio de Innovación que reparte la pasta, ¿vale? Aquí vendrá un político ahora y ha dicho, qué barbaridad acabas de decir. Resumo, es el organismo que reparte la pasta, ¿vale? Y ya está. Entonces, ahora, por ejemplo, el CEDETI lo que ha hecho es, hay una convocatoria ahora de gobiernos centrales de CEDETI que se llama Misiones y se llaman Misiones porque hay diferentes verticales dentro de la convocatoria. Misiones Medio Ambiente, Misiones Construcción, Misiones Establishment y hay una que es Misiones Defensa. Pues, este año, la bolsa de dinero que tiene Misiones Defensa ha hecho así. O sea, estos son los últimos años y este año Misiones Defensa ha hecho pum, en relación con lo que decía la compañera. Entonces, concretamente, lo presenté hace 2 semanas. Yo he presentado un proyecto ahora con Airbus en defensa, ¿vale? Es un proyecto para defensa y, Jenny, es para defensa, pero es para la optimización. de la fabricación de los aviones de defensa de Airbus, ¿vale? No es directamente temas de acción de guerra, por decirlo así, es de la fabricación de los aviones de ataque que fabrica Airbus. Concretamente hemos presentado Cirisa-I, Airbus y dos empresas más y hemos presentado un sistema de simulación, como lo que estamos hablando antes. Es un planificador inteligente de la producción del avión, ¿vale? Ya hemos metido ahí toda la chicha, hemos metido Explainable, hemos metido hemos metido un sistema que ni me acuerdo, una nueva tendencia que hay también en investigación en Europa, autoetiquetado, autoetiquetado de redes neuronales, bueno hemos metido ahí varias cosas bastante chulas, porque hay que meter carnaza de innovación para que el evaluador, el evaluador están muy puestos en lo que hay, para que lo vean y digan, o sea, esto es pilota, ¿vale? Y lo hemos presentado ya. Entonces, en defensa, Jenny, estoy en eso, ¿vale? Es decir, no como ya os he dicho antes los sectores, no he mencionado defensa, tampoco estoy en defensa, pero estoy en eso, porque es defensa pero es industria, o sea, es fabricación del propio avión, entonces vamos a estar ahí. Y también estoy en, porque se han asociado con nosotros esto, en el grupo Inversion libanés que os decía antes, en inspección de pistas de aterrizaje militares, ¿vale? Con sistemas de visión artificial, para inspeccionar el pavimento de las pistas de las pistas de despegue, FOTS, FOTS son una especie como de cuerpos extraños, objetos que no deban estar en el pavimento y están y aparecen, y luego todo lo que es infraestructura, luces, marcas viales, señalización, etcétera, etcétera. Con un vehículo, ponemos un set de cámaras en la parte del vehículo y inspeccionamos toda la infraestructura. Me da mucha rabia porque, claro, todo esto lo podéis necesitar más días, pero que... El año que viene te invitamos dos, ¿va? Encantado, pero que quiero decir, es que son muchas cosas, pero sí estamos ahí. Entonces, esto es una aplicación a nivel de visión artificial, Jenny, ¿vale? Para hacer toda esta inspección. Y en defensa es en lo que estamos, es decir, que no somos una empresa orientada a defensa, pero estamos en esto, ¿vale? Pues me he olvidado tu nombre. ¿Joana? Sí, de lo que dijiste a mí me interesa el tema de explicabilidad, porque es algo que he estado estudiando, bueno, con Jenny también, pero desde ángulo distinto y lo hemos estado conversando. Ella está estudiando más en los modelos de caja blanca, como los árboles de decisión, la explicabilidad, y yo lo he tomado más desde GradCam, Attention y Descenso de Gradiente, porque lo he estado haciendo en redes neuronales y en Transformer, que es como mi fascinación. Entonces quería saber para qué específicamente están aplicando ustedes la explicabilidad. Entiendo lo que dijiste ahora, que en defensa me parece muy relevante, de hecho es lo que está haciendo Jenny en su proyecto de tesis, pero me interesa también saber en otras áreas, ¿qué están pidiendo los clientes con respecto a explicabilidad? ¿Conocéis la prescripción? Cuando hablamos de inteligencia artificial y de análisis predictivo, lo primero que viene a nuestra cabeza, y lo primero que os estoy contando, es la predicción, ¿no? Los análisis predictivos, ¿qué predicen? Luego hay un siguiente paso que se implementa principalmente con modelos de explicabilidad, ¿vale? Que son modelos no predictores, sino prescriptores. ¿Qué hacen los modelos prescriptores? Lo que hacen es sacar la inferencia que ha sacado el predictor, coger los resultados del modelo de explicabilidad y generar una prescripción utilizando unas librerías, una tecnología que se llama Knowledge Graphs, grafos de conocimiento. Esto a lo mejor si has tocado explicabilidad... Sí, sí, también he estado con eso. Me encanta el tema holografo, me fascina. Perfecto, pues entonces se utiliza mucho de la mano. Los Knowledge Graphs, que también es tendencia en investigación en Europa, se asocian muy bien con modelos directos de explicabilidad. Utilizando y enlazando explainable models y Knowledge Graphs puedes generar modelos prescriptivos, que es como la evolución de los modelos predictivos. Estamos aquí hablando de temas muy novedosos. El tipo de aplicación práctica que se utiliza con los prescription son aquellas situaciones en las cuales le estás pidiendo más a la inteligencia artificial. O sea, le estás pidiendo que no solo te diga que esa botella que está aquí en la mesa en 5 minutos se caerá, sino que con el modelo de explainable, ¿qué te está diciendo? Te está diciendo las variables que han originado que se haya caído esa botella. Pues cuando tú relacionas eso con un grafo de conocimiento, un Knowledge Graph, te permite obtener la prescripción. La prescripción es por qué se ha caído eso y cuando tienes el por qué puedes obtener ya la corrección. Básicamente se está utilizando para no es predecir, sino obtener el por qué y luego poder corregirlo de forma que esa botella nunca se llegue a caer. ¿Habéis visto el Minority Report? Sí, en el fondo tú evitas que algo malo pase porque predices que existen probabilidades altas de que algo malo pase. Entonces tú tomas medidas y así nunca pasa. Y claro, me imagino que con control de calidad debe ser muy importante porque te ahorras un montón de pasta si llegas a evitar que los productos salgan defectuosos en vez de estar arreglando el defecto después que siempre es más caro. Efectivamente, digamos que el Minority Report, lo que yo acabo de decir que es explainable con Knowledge Graph, que generas la prescripción y luego la corriges, lo que hacen ellos no es con la inteligencia artificial. Ahí busca el tipo y lo detiene. Pero digamos que aquí lo que estamos haciendo a nivel real es que, ya sea en máquinas, en procesos distribuidos, en cadena de suministro, estamos planteándolo en varios aspectos, lo que hacemos es generar esa explicación de las variables enlazadas al por qué y el por qué lo que hacemos es corregirlo. Básicamente, tú lo estabas identificando. Generamos que, predecimos que en dos días la máquina se va a averiar, generamos por qué se ha averiado y generamos al operario qué correcciones tiene que hacer en la máquina para que en dos días ese fallo ya no llegue a producirse. Hemos predecido el futuro y hemos cambiado el futuro, por decirlo así. Y ahora os voy a dar el giro de tuerca final. ¿Y si ni siquiera se lo decimos al operario? ¿Y si modificamos nosotros mismos las variables de la máquina? Estamos viendo un futuro, pero que ya es hipotético, porque es un futuro que es real, pero él mismo se ha corregido y ya no va a ocurrir. Y aquí nos ponemos en dos temas filosóficos. Hay mucha filosofía, mucha ética y mucha filosofía en este caso. Eso es. Iba a poner tu pregunta, ¿verdad? Ahí sí, que no se me había activado el micrófono. Lo encuentro súper interesante porque yo lo he estado viendo más que nada en temas de salud. Entonces, el poder hacer lo mismo que me gusta hacer, pero aplicado a otra industria, me parece súper interesante. Sí, te agradezco la visión porque como no son áreas que yo conozca, no se me había ocurrido aplicarlo en esas áreas. Pero sí que he trabajado mucho en control de calidad. Entonces, imagínate, si uno lo que estoy haciendo ahora en explicabilidad con el control de calidad, ahí habría un área interesante. Totalmente, totalmente. Y luego está los explainable aplicados a imagen, que también se utiliza. De hecho, tengo, no sé si os lo he puesto, pero en clase también hablo, en el otro máster que doy, también hablo de explainable en imagen, que es muy interesante. O sea, básicamente, cuando estás reconociendo, cuando tú pones una, digamos, redes neuronales con imagen, que tampoco voy a entrar en eso porque sería ahora otro hilo de conversación, pero que se aplican, tienen un encaje perfecto. Cuando tú entrenas una red neuronal convolucional, por ejemplo, y detecta, por ejemplo, el objeto casco, ¿no? Ha detectado el objeto casco y te dice lo que es, pero ¿cómo ha detectado que eso es un casco? Entonces, lo que en ese momento, con la aplicación de los explainable modes a imagen, lo que te hace es decirte que conjuntos de píxeles ha reconocido como especialmente determinantes para saber que eso es un casco. Sí, de hecho, eso es lo que te estaba diciendo, que cuando aplicaba GradCamp, y Descanso de Gradientes y el Attention, yo saco mapas de calor. Yo lo hice con un modelo de visión-lenguaje para temas de imágenes médicas, de todo tipo de imágenes médicas. Y son imágenes difíciles que tú a nivel normal, si no eres médico, no tienes idea qué hay ahí, porque son ecografías, sonogramas y tomografías, cosas muy complejas. Entonces el modelo me dice lo que está ahí, me describe la imagen, me describe los objetos, me los ubica inclusive. Pero el tema es que yo quería saber, bueno, ¿en qué te estás fijando para decirme eso? ¿Cómo sé yo que no estás alucinando? Entonces ahí me empecé a meter con los temas de explicabilidad y, claro, es súper chulo que te saque estos mapas de calor donde te dice dónde está mirando, porque tú así ya puedes corroborar eso. Y sí, efectivamente, ahí está el corazón, ahí está el hígado, ahí hay una masa que es un nódulo y bla, bla, bla. Entonces es súper interesante, pero claro, yo lo estaba aplicando en eso, en el área médica, no se me había ocurrido aplicarlo en otras áreas, ni sabía que lo estaban haciendo ya las industrias. Así que es muy interesante. Totalmente. En mapas de calor estamos implantando, digamos, interfaces con mapas de calor donde igual que en el cuerpo humano, como tú estabas diciendo, nosotros estamos pintando con mapas de calor el resultado de los explainable de la máquina. Donde te está diciendo, ha predicho que se ha averiado la máquina o que ha generado el defecto de calidad, pero automáticamente te pinta con mapa de calor qué componente es el que ha generado ese defecto o esa avería. Es muy interesante. Muy bien. Perfecto, continuamos, chicos. Vale, nos habíamos ido un poco por los cerros de dúvida, pero bueno, yo creo que la verdad es que son preguntas muy interesantes las que me estáis haciendo, que están muy relacionadas con mi trabajo y yo creo que la verdad es que son preguntas muy interesantes. que es genial todo lo que estamos contando. Yo antes de acabar sí que te recuerdo que me tienes que dejar 10 minutillos. 10 minutos para hablar de lo que te he comentado. Sí, sí, sí, por supuesto, por supuesto. Bueno, pues nada, deciros respecto a esto que los datos principales que tenéis que tener en cuenta a la hora, a nivel de un ingeniero de Machine Learning que sepa que tiene que obtener el segmento de entrenamiento y validación con los preprocesos de tal nombre. A nivel real para implantarlo, súper importante los datos de proceso, contexto, aplicación y explotación. Que sea el propio ingeniero quien los divida. Aquí tenéis la explicación un poco de dónde vienen. Los datos de proceso te dan la información del estado de la máquina mientras se encuentra en producción. Lo que hablaba ahora mismo con la compañera de ver un poco las variables vitales de la propia máquina, ¿vale? Sondas de temperatura, presostatos, acelerómetros, la vibración también es muy importante. Todo esto, medidas de potencia, etcétera, etcétera. Luego tenemos también, mira, esto es un ejemplo tal cual. Esto es un conector. Esto es un conector de datos de proceso real, ¿vale? De los nuestros. Esto es la única pantalla visible que se ve en un conector de datos de proceso de un modelo Machine Learning. Esto de aquí es toda la configuración en series temporales de todo el conjunto de variables. Si os fijáis, hay un segmento aquí de variables eosync. Eosync es un bus industrial que lo que hace es unir todas las variables. Esto viene en relación también a lo que estabais preguntando. Todo esto que pone eosync son sensórica adicional que le instalamos a la máquina. ¿Por qué? Porque cuando tú te pones a mirar una máquina y el cliente te dice, es que tengo este problema con la máquina, me está generando eso. Y sería genial ver el futuro de cuándo va a generar los efectos de calidad para que luego no ocurran. Tú te pones a ver con tus ingenieros y con los del cliente qué variantes disponibles hay. Pero a lo mejor la máquina, tú te vas al control interno de la máquina, al PLC, y tienes muchas variables interesantes, pero a lo mejor hay algunas que tú consideras que sean clave para entrenar el modelo de análisis predictivo que no están disponibles en el control de máquina interno. Entonces, en ese momento, ahí lo que nosotros hacemos es proponer una sensorización adicional a la máquina, ¿vale? Entonces, esa sensorización adicional en muchos casos es, a lo mejor, tan sencilla como coger y meterle un sensor de temperatura, ¿vale? Un sensor de temperatura y un acelerómetro. De forma que hemos visto que a lo mejor hay un servomotor que es interesante medir el nivel de vibración y medir la temperatura de otra parte de la máquina. Entonces, en este caso se sensorializaron algunas, hay bastantes más por abajo, por aquí. Y luego tenemos, por ejemplo, todas las posiciones de los ejes de una serie de operaciones de los husillos que se estaban haciendo a la pieza. Y tenemos, fijaros, mira, tenemos también el código de pieza, que eran datos de contexto. Pues sí, no estaba ahí. Eran datos de contexto, ¿vale? Entonces, tenemos datos de contexto y todos los datos de proceso, ¿vale? Y esto, si os fijáis, que lo pone por aquí, todo esto se está muestreando con 50, creo que son cada 100 milisegundos. O sea, cada 100 milisegundos el conector va leyendo todas estas variables y aquí tenéis el timestamp, ¿vale? De hecho, lo pondrá que pone por aquí. Cuando pone, mira. Pone ventana de envío, 1,000 milisegundos. Control de mostreo y trama. Mostreo de tags, 100 milisegundos. Ah, sí, exacto, 100 milisegundos, exacto. Imaginados la cantidad ingente de datos que está muestreando esto en solo un día. Solo un día muestreando datos de una máquina, ¿vale? Ayer nos decía Javi que cada coche genera 100. 150 gigas de imágenes y datos. 150 gigas por coche. 150 gigas, dependiendo de las características que se quiera inspeccionar, o sea, el nivel completo de todas las inspecciones. Ese tipo de sistemas también va parametrizado según lo que compren los clientes. Lo quiero todo o quiero solo estos módulos. Pero también 150 gigas, pero esto es algo también que digo en clase que es muy importante. Nos daría para hablar también bastante. Es completamente diferente lo que acaba de decir Ernesto a esto. ¿Por qué? Correcto. Una imagen, ¿cuánto ocupa en una secuencia de vídeo? Mucho más que el texto, que el dato plano. Muchísimo, muchísimo más. ¿Por qué? Porque una imagen tiene muchísima más información que un dato muestreado. Porque en una imagen, aparte de ser una matriz de píxeles que puede ser tanto o por tanto, cada píxel tiene una profundidad de bit. O sea, por eso de lo que oíamos de esto es una imagen a 16 bits, ¿qué significa que es una imagen a 16 bits? Significa que cada píxel tiene 2 elevado de 16 combinaciones de color. Entonces, genera una cantidad de datos muchísimo más grande y por eso el almacenamiento es mayor y por eso es la principal fuente de datos que tiene especial encaje con redes neuronales, lo que os decía al principio. Porque la cantidad de datos es muchísimo más grande que la de datos, digamos, de data. Muy bien, pues, a ver, yo creo que lo digo para dejar unos minutos para comentar lo que estabas diciendo, ¿vale, chicos? Yo creo que hasta aquí espero que os haya parecido interesante, por lo menos a mí me lo ha parecido. Yo creo que tenéis un nivelazo, me gustan mucho las preguntas que habéis dicho. ¿Tenéis mi contrato? Que lo había puesto ahí. Si no, Ernesto, os puede pasar mi correo personal, por si me queréis comentar algo. Y, nada, ha sido un placer y super, superinteresante. También, Ernesto, quería comentar algo ahora. ERNESTO SANCHEZ-TRUJILLO Sí, a ver, yo quería comentar lo que comento siempre, pensando en los alumnos que tenemos, el tema de contratos. O sea, es un poco, vale, habéis tenido un crecimiento dentro de la empresa, entonces, ¿en qué momento estáis de cara a contratación? ¿Qué tipo de perfiles buscáis? ¿Os interesan perfiles externos? ¿Perfiles que es autónomo, te contrato 20 horas, me haces este trabajo y luego cada uno va con lo suyo? O sea, yo, al final, dentro de este máster, lo que te decía antes en el pasillo, ya tenemos gente muy, muy preparada. De hecho, creo que pocos másters en, bueno, tengo que echar flores porque es que creo que es así. De verdad que lo creo, pocos másters que hay aquí. Y sé que alguno dirige otros másters, pero que tiene más de gestión de proyectos. Tienen el nivel que tienen aquí, han programado mucho Python y están muy puestos. Entonces, primero, ¿qué tipo de contratos tenéis, ofrecéis o creéis que va a venir en corto plazo? Y luego, ¿qué consejos darías para alguien que está empezando en este mundo? Tenemos perfiles de todo, ¿eh? Como bien ha dicho Jenny y Joanna, ellas ya están ahí. Hay otros que también y otros que no están. Entonces, bueno, pues, ¿qué consejos darías, no? Claro. Yo soy profe de otro máster, no lo dije antes. Ah, vale, vale, vale. Yo soy profesor. A ver, en primer lugar, por supuesto, yo veo que vais por muy buen camino y veo mucho nivel. Nosotros en GisAi, bueno, estamos en constante búsqueda de talento, nuevos recursos, nuevos perfiles. Yo creo que tenéis ahora todos una fotografía bastante buena de a lo que nos dedicamos. Entonces. El pavimento. Y esto es la operación de Stitch Intima. Es uno de los sistemas que os queríamos dar de provisión, de los que estamos implantando. Muy bien, chicos. Tengo aquí, quizás, no sé. Oh, qué chulo. Gracias. Para terminar la clase, en cuanto, bueno, tú comentas un poco de cómo empezaste, de cómo fue la historia de la empresa. Pero, ¿qué consejos puedes dar también a las personas que quieren emprender? Que tienen, quizás, una buena idea. Que, quizás, como yo digo, sin necesidad, bueno, te hice que hay también maneras de buscar, quizás, proyectos por parte de los open programas. ¿Los Open Innovation? Sí. Pero, aparte, también, cómo puedas buscar, quizás, tú que ya tienes igual una parte comercial, cómo también buscar clientes de poderles, quizás, llegar, quizás, venderles una idea de poder comprar un producto o servicio. Correcto. Totalmente. Totalmente. Hay que saber diferenciar entre buscar un cliente o buscar un partner o un inversor. Porque no es lo mismo. Entonces, claro, si tú tienes una idea, buscar un cliente puede ser beneficioso para ti o no, ¿vale? Porque si tú tienes una idea y el cliente te la compra, entre comillas, te va a comprar, pero te va a comprar el desarrollo. Entonces, tú, a partir de ahí, digo, como recomendación de lo que me estabas preguntando, a partir de ahí, para emprender tú, no teniendo el producto, sino teniendo la idea, puedes ir activando el producto. Bueno, es viable esa opción, pero te lo digo porque eso ocurre. Puedes irte, en lugar de inversores, grupos de inversión que directamente lo que hacen es poner la oreja y escuchar, como se ha hecho toda la vida, ¿no? Pero tú también puedes ir por la otra vía. En vez de inversores, puedes ir a clientes y les puedes presentar. Si el cliente lo acepta, te va a poner dinero ahí el cliente, pero el cliente probablemente te va a decir, estoy pagando el desarrollo. Y seguramente se va a quedar el 100% de la propiedad. Ahí tú también te tienes que poner fuerte porque tú tienes, y eso es una cosa que les digo yo en negociaciones, a mis cuentas, a mis clientes, ellos están pagando, en muchos casos, el desarrollo, pero no me está pagando todo el conocimiento previo. ¿Qué hace que yo pueda desarrollar todo eso? Y eso se tiene que corresponder a un porcentaje de la propiedad. Entonces, ahí es donde tú lo tienes que jugar fuerte para poder crearte un porcentaje de la propiedad y, obviamente, algo ellos porque te pagan el desarrollo. Y a partir de ahí, tú ya puedes empezar a dar pasos de desarrollo de negocio con el cliente. Y luego, obviamente, las otras alternativas, pues, que no hay que tener muchos de inversión y demás. Manu, permíteme que diga, hay 2 conceptos más que son interesantes para esto cuando tienes una idea y has desarrollado una parte, que son toda la parte de garajes, que se le domina normalmente, que es la parte que te dan un sitio y te aconsejan, ¿no? Y a veces te dan de recursos. Y luego está toda la parte de lanzaderas y tal. Incubadoras. Incubadoras. Y, bueno, aquí está lanzadera también. En la Universidad Europea también tenemos alguna. ¿Conocéis? Está en Sonia, en la Marina también. Efectivamente. Entonces, ese tipo es otra de lo que te ha comentado él, por supuesto. Y luego tienes esas 2 vías alternativas. Puedes ir con tu idea, te ayudan a realizarla, te subvencionan o financian una parte y luego ya si es muy buena invierten incluso. Y eso ya tienes que ir viendo, ¿no? Claro. Es que yo también voy como enfocado a la parte que si uno ya tiene desarrollado el servicio o el producto que ofrece, pues, claro, pues, si vamos, uno puede crear una empresa, una startup. Pero, pues, ¿cómo le va a crear una empresa a una empresa pequeñita que primero? no tiene un cliente, tú estás ofreciendo y vendiendo un servicio, aparte digamos, comprarlo. Yo me imagino que usted ya como empresa, buscan empresas nuevas, clientes nuevos, en donde bueno, ya tienen un portafolio, pero pues quizás también ese consejo de decir, bueno, hay una vía que listo, no puedo tener un servicio, hay una parte de promoción, de marketing, etcétera, etcétera, pues también sería bueno escuchar ese consejo de un CEO de una empresa, de cómo también, si yo tengo pues un producto determinado, aparte de la promoción, cómo poderle llegar, quizás también a esos clientes. Bueno, la parte comercial, quizás, yo ya tiene un consejo. La parte comercial, vale. Sí, a ver, la parte comercial hay, yo te voy a decir cosas que veo, pero yo no empecé así. Sí, sí. Yo empecé así, o sea, yo empecé, lo podéis imaginar, yo empecé con mis productos en la promoción, tenía productos en la promoción y tenían buen recuerdo de mí, había una buena relación, empecé moviendo eso. Y luego empecé moviéndome por programas de innovación abierta. Como os comentaba antes, que, insisto, son muy inteligentes, tenéis que saber gestionarlos, pero son muy interesantes, perdón, estoy con los inteligentes todo el rato. Interesantes, son muy interesantes. Entonces, luego, a partir de ahí también hay agencias de desarrollo de negocio concretas para lo que estás diciendo. Son agencias que lo que hacen es coger y te ponen, te estudian tu producto y te dicen, te pongo sobre la mesa todos estos leads. Te dan un conjunto de leads, ojo, a precio por lead. Pero son precios, es decir, razonables porque son de pocos cientos de euros. Son pocos cientos de euros por lead. Un lead es un lead, no confundir lo que es un lead. Un lead es... Ya no vas a puertas frías, sabes que está ahí y que algo de interés tendrá. Efectivamente, pues eso es un lead. Como mucho te pueden acompañar en la primera reunión o en la segunda, pero tú eres el que tiene que ganar la batalla y ya con él. Y eso a mí se me han llamado muchas empresas a la puerta a lo largo de los años que ofrecían este tipo de servicio de desarrollo de negocio. No he utilizado un año que estuve utilizando alguno. No fue mal, pero digamos que un poco por ya todas las ramificaciones que tenemos nosotros nos movemos más eficiente de otra forma. Pero hay mucha gente que está utilizando de esta forma y le ha funcionado muy bien. Conozco una empresa a nivel de desarrollo de plataformas de texto, que es de streaming de vídeo y todo eso, que empezó con una empresa de esta, Lentelis. Les pasó un lead de un botánico de televisión menos que. Empezaron a trabajar y con ellos están trabajando hace cuantos años, han crecido con ellos. Entonces, en un modo de ver las características de cada uno, pero eso también es una muy buena opción para las empresas de este tipo. Chicos, encantado. Ha sido un placer. Y a los que estáis en remoto, ha sido un placer y estamos en contacto. Vamos hablando. Gracias. Vale. Seguro que sí. Gracias. Muchas gracias. Muchas gracias. Gracias, genial. Hasta luego. ¿Tenemos ahí detrás? Voy a parar la grabación, que si no esto... ¿Queréis? Es que así estamos muy distribuidos aquí.